{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "coso = pd.read_csv('coso.csv')\n",
    "new0 = pd.read_csv('New_DB_new0.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "new0 = new0[['PP', 'slope', 'valor_humedad_suelo1', 'Latitud', 'Longitud']].dropna()\n",
    "coso = coso[['PP', 'slope', 'valor_humedad_suelo1', 'Latitud', 'Longitud']].dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_0 = pd.read_csv('xterrae_data_0').dropna()\n",
    "data_1 = pd.read_csv('xterrae_data_1').dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PP</th>\n",
       "      <th>slope</th>\n",
       "      <th>valor_humedad_suelo1</th>\n",
       "      <th>Latitud</th>\n",
       "      <th>Longitud</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>71.563169</td>\n",
       "      <td>23.981049</td>\n",
       "      <td>0.438995</td>\n",
       "      <td>-39.597580</td>\n",
       "      <td>-72.260578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>71.563169</td>\n",
       "      <td>26.626618</td>\n",
       "      <td>0.438995</td>\n",
       "      <td>-39.598738</td>\n",
       "      <td>-72.254661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>71.563169</td>\n",
       "      <td>28.545852</td>\n",
       "      <td>0.438995</td>\n",
       "      <td>-39.582146</td>\n",
       "      <td>-72.258995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>71.563169</td>\n",
       "      <td>28.545852</td>\n",
       "      <td>0.438995</td>\n",
       "      <td>-39.580483</td>\n",
       "      <td>-72.272591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.532796</td>\n",
       "      <td>35.594937</td>\n",
       "      <td>0.438187</td>\n",
       "      <td>-39.561471</td>\n",
       "      <td>-72.286932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1355</th>\n",
       "      <td>1.167900</td>\n",
       "      <td>45.373746</td>\n",
       "      <td>0.352768</td>\n",
       "      <td>-39.615112</td>\n",
       "      <td>-73.198518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1356</th>\n",
       "      <td>1.054908</td>\n",
       "      <td>28.705555</td>\n",
       "      <td>0.313675</td>\n",
       "      <td>-39.663321</td>\n",
       "      <td>-73.166174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1357</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>35.755171</td>\n",
       "      <td>0.306458</td>\n",
       "      <td>-39.556847</td>\n",
       "      <td>-73.134727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1358</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>40.502730</td>\n",
       "      <td>0.335510</td>\n",
       "      <td>-39.460378</td>\n",
       "      <td>-73.158058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1359</th>\n",
       "      <td>0.014927</td>\n",
       "      <td>36.260335</td>\n",
       "      <td>0.438995</td>\n",
       "      <td>-39.661098</td>\n",
       "      <td>-72.557143</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1351 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             PP      slope  valor_humedad_suelo1    Latitud   Longitud\n",
       "0     71.563169  23.981049              0.438995 -39.597580 -72.260578\n",
       "1     71.563169  26.626618              0.438995 -39.598738 -72.254661\n",
       "2     71.563169  28.545852              0.438995 -39.582146 -72.258995\n",
       "3     71.563169  28.545852              0.438995 -39.580483 -72.272591\n",
       "4      7.532796  35.594937              0.438187 -39.561471 -72.286932\n",
       "...         ...        ...                   ...        ...        ...\n",
       "1355   1.167900  45.373746              0.352768 -39.615112 -73.198518\n",
       "1356   1.054908  28.705555              0.313675 -39.663321 -73.166174\n",
       "1357   0.000000  35.755171              0.306458 -39.556847 -73.134727\n",
       "1358   0.000000  40.502730              0.335510 -39.460378 -73.158058\n",
       "1359   0.014927  36.260335              0.438995 -39.661098 -72.557143\n",
       "\n",
       "[1351 rows x 5 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_0 = pd.merge(new0, data_0, on=['Latitud', 'Longitud'], how='inner')\n",
    "data_1 = pd.merge(coso, data_1, on=['Latitud', 'Longitud'], how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_0 = data_0.drop(columns=['Unnamed: 0', 'Latitud', 'Longitud'])\n",
    "data_1 = data_1.drop(columns=['Unnamed: 0', 'Latitud', 'Longitud'])\n",
    "data_0['Valor'] = 0\n",
    "data_1['Valor'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_db = pd.read_csv('final_db.csv')\n",
    "final_db = final_db.drop(columns='Unnamed: 0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def comparar_columnas(df1, df2):\n",
    "    # Obtener los nombres de las columnas en cada DataFrame\n",
    "    columnas_df1 = set(df1.columns)\n",
    "    columnas_df2 = set(df2.columns)\n",
    "    \n",
    "    # Encontrar columnas que están en df1 pero no en df2\n",
    "    solo_en_df1 = columnas_df1 - columnas_df2\n",
    "    \n",
    "    # Encontrar columnas que están en df2 pero no en df1\n",
    "    solo_en_df2 = columnas_df2 - columnas_df1\n",
    "    \n",
    "    # Imprimir los resultados\n",
    "    if solo_en_df1:\n",
    "        print(\"Columnas en df1 pero no en df2:\")\n",
    "        for columna in solo_en_df1:\n",
    "            print(columna)\n",
    "    else:\n",
    "        print(\"Todas las columnas de df1 están en df2.\")\n",
    "    \n",
    "    if solo_en_df2:\n",
    "        print(\"Columnas en df2 pero no en df1:\")\n",
    "        for columna in solo_en_df2:\n",
    "            print(columna)\n",
    "    else:\n",
    "        print(\"Todas las columnas de df2 están en df1.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Todas las columnas de df1 están en df2.\n",
      "Todas las columnas de df2 están en df1.\n"
     ]
    }
   ],
   "source": [
    "comparar_columnas(final_db,data_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Todas las columnas de df1 están en df2.\n",
      "Todas las columnas de df2 están en df1.\n"
     ]
    }
   ],
   "source": [
    "comparar_columnas(final_db,data_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "final = pd.concat([final_db, data_0])\n",
    "final = pd.concat([final, data_1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "final = final.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_x = final.drop(columns='Valor')\n",
    "final_y = final.Valor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Umbral  Caracteristicas eliminadas\n",
      "0    0.10                         136\n",
      "1    0.20                         135\n",
      "2    0.30                         131\n",
      "3    0.40                         130\n",
      "4    0.50                         128\n",
      "5    0.60                         128\n",
      "6    0.70                         122\n",
      "7    0.80                         113\n",
      "8    0.90                          91\n",
      "9    0.99                          38\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def eliminar_caracteristicas(df, umbral):\n",
    "    \"\"\"\n",
    "    Elimina características de un DataFrame basado en la correlación.\n",
    "    \n",
    "    Args:\n",
    "    - df (pd.DataFrame): DataFrame con las características.\n",
    "    - umbral (float): Umbral de correlación para eliminar características.\n",
    "    \n",
    "    Returns:\n",
    "    - pd.DataFrame: DataFrame con las características restantes.\n",
    "    - int: Número de características eliminadas.\n",
    "    \"\"\"\n",
    "    # Calcular la matriz de correlación\n",
    "    correlaciones = df.corr().abs()\n",
    "    \n",
    "    # Crear una máscara para evitar considerar la diagonal principal\n",
    "    mask = np.triu(np.ones_like(correlaciones, dtype=bool), k=1)\n",
    "    \n",
    "    # Identificar pares de características con alta correlación\n",
    "    to_drop = set()\n",
    "    for i in range(len(correlaciones.columns)):\n",
    "        for j in range(i):\n",
    "            if correlaciones.iloc[i, j] > umbral:\n",
    "                colname = correlaciones.columns[i]\n",
    "                to_drop.add(colname)\n",
    "    \n",
    "    # Eliminar las características\n",
    "    df_reducido = df.drop(columns=to_drop)\n",
    "    \n",
    "    # Número de características eliminadas\n",
    "    num_eliminadas = len(to_drop)\n",
    "    \n",
    "    return df_reducido, num_eliminadas\n",
    "\n",
    "def prueba_umbral(df, umbrales):\n",
    "    \"\"\"\n",
    "    Prueba diferentes umbrales y guarda el número de características eliminadas.\n",
    "    \n",
    "    Args:\n",
    "    - df (pd.DataFrame): DataFrame con las características.\n",
    "    - umbrales (list): Lista de umbrales para probar.\n",
    "    \n",
    "    Returns:\n",
    "    - pd.DataFrame: DataFrame con los resultados de la prueba.\n",
    "    \"\"\"\n",
    "    resultados = []\n",
    "    \n",
    "    for umbral in umbrales:\n",
    "        df_reducido, num_eliminadas = eliminar_caracteristicas(df, umbral)\n",
    "        resultados.append({'Umbral': umbral, 'Caracteristicas eliminadas': num_eliminadas})\n",
    "    \n",
    "    return pd.DataFrame(resultados)\n",
    "\n",
    "# Ejemplo de uso:\n",
    "# df = pd.DataFrame(...)  # Reemplaza con tu DataFrame real\n",
    "umbrales = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 0.99]\n",
    "resultados = prueba_umbral(final, umbrales)\n",
    "\n",
    "print(resultados)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reducido, num_eliminadas = eliminar_caracteristicas(final, 0.99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "final = df_reducido"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "    def cart_feature_selection(df, target_column, n_features=5):\n",
    "        X = df.drop(target_column, axis=1)\n",
    "        y = df[target_column]\n",
    "        \n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "        \n",
    "        cart = RandomForestClassifier(random_state=42)\n",
    "        #cart = XGBClassifier(random_state=42)\n",
    "        cart.fit(X_train, y_train)\n",
    "        \n",
    "        feature_importance = pd.DataFrame({\n",
    "            'feature': X.columns,\n",
    "            'importance': cart.feature_importances_\n",
    "        }).sort_values('importance', ascending=False)\n",
    "        \n",
    "        selected_features = feature_importance['feature'][:n_features].tolist()\n",
    "        \n",
    "        return selected_features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['slope',\n",
       " 'valor_humedad_suelo1',\n",
       " 'PP',\n",
       " 'ksat_60-100cm.tif',\n",
       " 'PIRange_Clay.15-30cm.tif',\n",
       " 'PIRange_Bulkd.60-100cm.tif',\n",
       " 'PIRange_Clay.30-60cm.tif',\n",
       " 'PIRange_Clay.0-5cm.tif',\n",
       " 'PIRange_Clay.100-200cm.tif',\n",
       " 'PIRange_Clay.60-100cm.tif',\n",
       " 'Bulkd.60-100cm.tif',\n",
       " 'PIRange_Bulkd.5-15cm.tif',\n",
       " 'Clay.5-15cm.tif',\n",
       " 'Clay.15-30cm.tif',\n",
       " 'PIRange_Bulkd.100-200cm.tif',\n",
       " 'PIRange_Sand.15-30cm.tif',\n",
       " 'Clay.0-5cm.tif',\n",
       " 'Silt.15-30cm.tif',\n",
       " 'n_30-60cm.tif',\n",
       " 'PIRange_Sand.30-60cm.tif',\n",
       " 'n_5-15cm.tif',\n",
       " 'PIRange_Sand.60-100cm.tif',\n",
       " 'Bulkd.15-30cm.tif',\n",
       " 'PIRange_Sand.0-5cm.tif',\n",
       " 'ksat_100-200cm.tif',\n",
       " 'AvMoist.60-100cm.tif',\n",
       " 'ksat_5-15cm.tif',\n",
       " 'Sand.0-5cm.tif',\n",
       " 'n_60-100cm.tif',\n",
       " 'ksat.15-30cm.tif']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cart_features = cart_feature_selection(final, 'Valor', n_features=30)\n",
    "cart_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = final[cart_features]\n",
    "y = final.Valor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numero de entrenamiendo: (2518, 30), Numero de test: (630, 30)\n",
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n",
      "Precisión de 84.92063492063492\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "param_grid = {\n",
    "    'max_depth': [3, 5, 7, 10],\n",
    "    'learning_rate': [0.01, 0.1, 0.2, 0.3],\n",
    "    'n_estimators': [100, 200, 300, 500],\n",
    "    'subsample': [0.6, 0.8, 1.0],\n",
    "    'colsample_bytree': [0.6, 0.8, 1.0],\n",
    "    'gamma': [0, 0.1, 0.2, 0.3],\n",
    "    'reg_alpha': [0, 0.1, 0.5, 1.0],\n",
    "    'reg_lambda': [0, 1.0, 10.0]\n",
    "}\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "print(f'Numero de entrenamiendo: {X_train.shape}, Numero de test: {X_test.shape}')\n",
    "model = XGBClassifier()\n",
    "random_search = RandomizedSearchCV(model, param_distributions=param_grid, n_iter=50, scoring='accuracy', cv=5, verbose=1, random_state=42)\n",
    "random_search.fit(X_train, y_train)\n",
    "best_model = random_search.best_estimator_\n",
    "y_pred = best_model.predict(X_test)\n",
    "acc = accuracy_score(y_true=y_test, y_pred=y_pred)\n",
    "print(f'Precisión de {acc*100}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "predictions = best_model.predict(X_test)\n",
    "cm = confusion_matrix(y_test, predictions)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "disp.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ivo\\AppData\\Local\\Temp\\ipykernel_13256\\1511315089.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['Valor'] = final.Valor\n"
     ]
    }
   ],
   "source": [
    "data = final[cart_features]\n",
    "data['Valor'] = final.Valor\n",
    "data_aux_1 = data[data.Valor == 1]\n",
    "data_aux_0 = data[data.Valor == 0]\n",
    "data_aux_0 = data_aux_0.drop(columns='Valor')\n",
    "data_aux_1 = data_aux_1.drop(columns='Valor')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted probabilities: [0.2 0.  0.2 ... 0.2 0.2 0.6]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "class PUBagging:\n",
    "    def __init__(self, num_iterations=10, sample_ratio=1.0, random_state=42):\n",
    "        self.num_iterations = num_iterations\n",
    "        self.sample_ratio = sample_ratio\n",
    "        self.random_state = random_state\n",
    "        self.classifiers = []\n",
    "        self.probabilities = None\n",
    "\n",
    "    def fit(self, landslide_samples, unlabeled_samples):\n",
    "        np.random.seed(self.random_state)\n",
    "\n",
    "        if isinstance(landslide_samples, np.ndarray):\n",
    "            landslide_samples_array = landslide_samples\n",
    "        else:\n",
    "            landslide_samples_array = landslide_samples.values  # Convert to numpy array if it's a DataFrame\n",
    "\n",
    "        if isinstance(unlabeled_samples, np.ndarray):\n",
    "            unlabeled_samples_array = unlabeled_samples\n",
    "        else:\n",
    "            unlabeled_samples_array = unlabeled_samples.values  # Convert to numpy array if it's a DataFrame\n",
    "\n",
    "        num_samples = len(landslide_samples_array)\n",
    "        num_unlabeled = len(unlabeled_samples_array)\n",
    "\n",
    "        for _ in range(self.num_iterations):\n",
    "            # Step 1: Sample equal number of unlabeled samples as non-landslide samples\n",
    "            non_landslide_indices = np.random.choice(num_unlabeled, size=int(num_samples * self.sample_ratio), replace=False)\n",
    "            non_landslide_samples = unlabeled_samples_array[non_landslide_indices]\n",
    "\n",
    "            # Combine with landslide samples to form training set\n",
    "            X_train = np.vstack((landslide_samples_array, non_landslide_samples))\n",
    "            y_train = np.hstack((np.ones(num_samples), np.zeros(len(non_landslide_samples))))\n",
    "\n",
    "            # Step 2: Train decision tree classifier\n",
    "            clf = DecisionTreeClassifier(random_state=self.random_state)\n",
    "            clf.fit(X_train, y_train)\n",
    "            self.classifiers.append(clf)\n",
    "\n",
    "            # Step 3: Predict probability of being landslide for unlabeled samples\n",
    "            prob_landslide = clf.predict_proba(unlabeled_samples_array)[:, 1]\n",
    "\n",
    "            if self.probabilities is None:\n",
    "                self.probabilities = prob_landslide\n",
    "            else:\n",
    "                self.probabilities += prob_landslide\n",
    "\n",
    "        # Step 4: Average probabilities over iterations\n",
    "        self.probabilities /= self.num_iterations\n",
    "\n",
    "    def predict_proba(self, unlabeled_samples):\n",
    "        if isinstance(unlabeled_samples, np.ndarray):\n",
    "            return self.probabilities\n",
    "        else:\n",
    "            return self.probabilities[:len(unlabeled_samples)]  # Return probabilities for original DataFrame\n",
    "\n",
    "# Example usage:\n",
    "if __name__ == '__main__':\n",
    "    import pandas as pd\n",
    "    \n",
    "    # Example data (replace with your own data)\n",
    "    landslide_samples = data_aux_1# Example landslide samples as DataFrame\n",
    "    unlabeled_samples = data_aux_0# Example unlabeled samples as DataFrame\n",
    "\n",
    "    # Create PU Bagging instance\n",
    "    pu_bagging = PUBagging(num_iterations=5, sample_ratio=0.4, random_state=42)\n",
    "\n",
    "    # Fit the model\n",
    "    pu_bagging.fit(landslide_samples, unlabeled_samples)\n",
    "\n",
    "    # Predict probabilities for unlabeled samples\n",
    "    probabilities = pu_bagging.predict_proba(unlabeled_samples)\n",
    "    print(\"Predicted probabilities:\", probabilities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.2, 0. , 0.2, ..., 0.2, 0.2, 0.6])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Muestras no deslizamiento seleccionadas:\n",
      "          slope  valor_humedad_suelo1          PP  ksat_60-100cm.tif  \\\n",
      "0     32.357300              0.421875   13.532034         282.394012   \n",
      "1     32.357300              0.438995  238.139918         282.394012   \n",
      "2     37.497812              0.520004   32.059045         144.182007   \n",
      "3     36.717389              0.478973    0.000000          90.413002   \n",
      "4     60.517945              0.438095    2.191190         343.306000   \n",
      "...         ...                   ...         ...                ...   \n",
      "1162  24.327043              0.416611    0.674241         279.865997   \n",
      "1163  24.327043              0.416611    0.674241         261.084015   \n",
      "1164  24.641348              0.313675    1.054908         252.315994   \n",
      "1166  35.755171              0.306458    0.000000         120.091003   \n",
      "1167  40.502730              0.335510    0.000000         119.821999   \n",
      "\n",
      "      PIRange_Clay.15-30cm.tif  PIRange_Bulkd.60-100cm.tif  \\\n",
      "0                    22.490000                       0.650   \n",
      "1                    22.490000                       0.650   \n",
      "2                    25.268002                       0.706   \n",
      "3                    25.813000                       0.656   \n",
      "4                    18.743000                       0.660   \n",
      "...                        ...                         ...   \n",
      "1162                 25.160000                       0.648   \n",
      "1163                 25.082001                       0.644   \n",
      "1164                 24.950001                       0.642   \n",
      "1166                 26.760998                       0.657   \n",
      "1167                 27.098000                       0.669   \n",
      "\n",
      "      PIRange_Clay.30-60cm.tif  PIRange_Clay.0-5cm.tif  \\\n",
      "0                    26.009001               22.358000   \n",
      "1                    26.009001               22.358000   \n",
      "2                    31.559998               23.513000   \n",
      "3                    32.742996               25.056000   \n",
      "4                    21.934999               21.844999   \n",
      "...                        ...                     ...   \n",
      "1162                 31.753998               26.663998   \n",
      "1163                 31.809002               26.491001   \n",
      "1164                 31.700001               28.490000   \n",
      "1166                 33.229000               25.836998   \n",
      "1167                 33.653000               28.064001   \n",
      "\n",
      "      PIRange_Clay.100-200cm.tif  PIRange_Clay.60-100cm.tif  ...  \\\n",
      "0                      32.235001                  29.312000  ...   \n",
      "1                      32.235001                  29.312000  ...   \n",
      "2                      32.325001                  38.309998  ...   \n",
      "3                      45.129002                  39.369003  ...   \n",
      "4                      30.417000                  25.006001  ...   \n",
      "...                          ...                        ...  ...   \n",
      "1162                   45.535004                  38.932999  ...   \n",
      "1163                   45.632999                  39.013000  ...   \n",
      "1164                   47.789001                  38.739998  ...   \n",
      "1166                   44.098999                  39.952000  ...   \n",
      "1167                   45.316002                  40.355000  ...   \n",
      "\n",
      "      n_5-15cm.tif  PIRange_Sand.60-100cm.tif  Bulkd.15-30cm.tif  \\\n",
      "0            1.520                  44.574001              0.546   \n",
      "1            1.520                  44.574001              0.546   \n",
      "2            1.370                  46.751999              0.628   \n",
      "3            1.297                  37.791000              0.819   \n",
      "4            1.490                  42.887001              0.881   \n",
      "...            ...                        ...                ...   \n",
      "1162         1.362                  46.179001              0.726   \n",
      "1163         1.403                  45.993000              0.731   \n",
      "1164         1.357                  46.297001              0.824   \n",
      "1166         1.435                  46.610001              0.775   \n",
      "1167         1.350                  47.349998              0.792   \n",
      "\n",
      "      PIRange_Sand.0-5cm.tif  ksat_100-200cm.tif  AvMoist.60-100cm.tif  \\\n",
      "0                  36.184998          281.420990                 0.192   \n",
      "1                  36.184998          281.420990                 0.192   \n",
      "2                  36.636002          211.070007                 0.206   \n",
      "3                  34.499001           69.678001                 0.224   \n",
      "4                  36.883003          310.122009                 0.178   \n",
      "...                      ...                 ...                   ...   \n",
      "1162               36.374001          203.218994                 0.283   \n",
      "1163               36.174000          202.332993                 0.273   \n",
      "1164               36.351997          237.783997                 0.261   \n",
      "1166               37.070000           91.015999                 0.237   \n",
      "1167               38.124001           89.086998                 0.216   \n",
      "\n",
      "      ksat_5-15cm.tif  Sand.0-5cm.tif  n_60-100cm.tif  ksat.15-30cm.tif  \n",
      "0          315.993988       73.273003           1.446             0.606  \n",
      "1          315.993988       73.273003           1.446             0.606  \n",
      "2          211.750000       52.570000           1.372             0.396  \n",
      "3           78.719002       16.400000           1.334             0.123  \n",
      "4          239.182999       74.706001           1.510             0.569  \n",
      "...               ...             ...             ...               ...  \n",
      "1162       131.238998       28.066999           1.436             0.211  \n",
      "1163       144.242004       31.349001           1.430             0.237  \n",
      "1164       120.066002       33.570000           1.402             0.250  \n",
      "1166        58.084000       32.094002           1.403             0.246  \n",
      "1167        94.242996       45.729000           1.389             0.320  \n",
      "\n",
      "[1327 rows x 30 columns]\n"
     ]
    }
   ],
   "source": [
    "# Suponiendo que ya tienes las probabilidades predichas por pu_bagging.predict_proba(unlabeled_samples)\n",
    "\n",
    "# Umbral para seleccionar muestras no deslizamiento\n",
    "threshold = 0.5  # Puedes ajustar este umbral según tus necesidades\n",
    "\n",
    "# Filtrar muestras no deslizamiento por debajo del umbral\n",
    "non_landslide_indices = np.where(probabilities < threshold)[0]\n",
    "selected_non_landslide_samples = unlabeled_samples.iloc[non_landslide_indices]\n",
    "\n",
    "# Ejemplo de cómo podrías utilizar las muestras seleccionadas\n",
    "print(\"Muestras no deslizamiento seleccionadas:\")\n",
    "print(selected_non_landslide_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ivo\\AppData\\Local\\Temp\\ipykernel_13256\\38701351.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  selected_non_landslide_samples['Valor'] = 0\n"
     ]
    }
   ],
   "source": [
    "selected_non_landslide_samples['Valor'] = 0\n",
    "data_aux_1['Valor'] = 1\n",
    "\n",
    "data = pd.concat([data_aux_1, selected_non_landslide_samples])\n",
    "data_y = data['Valor']\n",
    "data = data.drop(columns=['Valor'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numero de entrenamiendo: (2356, 30), Numero de test: (589, 30)\n",
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n",
      "Precisión de 87.94567062818336\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "param_grid = {\n",
    "    'max_depth': [3, 5, 7, 10],\n",
    "    'learning_rate': [0.01, 0.1, 0.2, 0.3],\n",
    "    'n_estimators': [100, 200, 300, 500],\n",
    "    'subsample': [0.6, 0.8, 1.0],\n",
    "    'colsample_bytree': [0.6, 0.8, 1.0],\n",
    "    'gamma': [0, 0.1, 0.2, 0.3],\n",
    "    'reg_alpha': [0, 0.1, 0.5, 1.0],\n",
    "    'reg_lambda': [0, 1.0, 10.0]\n",
    "}\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, data_y, test_size=0.2)\n",
    "print(f'Numero de entrenamiendo: {X_train.shape}, Numero de test: {X_test.shape}')\n",
    "model = XGBClassifier()\n",
    "random_search = RandomizedSearchCV(model, param_distributions=param_grid, n_iter=50, scoring='accuracy', cv=5, verbose=1, random_state=42)\n",
    "random_search.fit(X_train, y_train)\n",
    "best_model = random_search.best_estimator_\n",
    "y_pred = best_model.predict(X_test)\n",
    "acc = accuracy_score(y_true=y_test, y_pred=y_pred)\n",
    "print(f'Precisión de {acc*100}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de entrenamiento: (2356, 30), Número de test: (589, 30)\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Precisión: 86.08%\n",
      "Mejores hiperparámetros encontrados:\n",
      "colsample_bytree: 0.6\n",
      "gamma: 0.0\n",
      "learning_rate: 0.02582116872265437\n",
      "max_depth: 10\n",
      "n_estimators: 500\n",
      "reg_alpha: 0.0\n",
      "reg_lambda: 0.0\n",
      "subsample: 1.0\n",
      "F1-score: 0.8602\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from xgboost import XGBClassifier\n",
    "from skopt import BayesSearchCV\n",
    "from skopt.space import Real, Integer, Categorical\n",
    "\n",
    "# Definir el espacio de búsqueda para los hiperparámetros\n",
    "param_space = {\n",
    "    'max_depth': Integer(3, 10),\n",
    "    'learning_rate': Real(0.01, 0.3, prior='log-uniform'),\n",
    "    'n_estimators': Integer(100, 500),\n",
    "    'subsample': Real(0.6, 1.0),\n",
    "    'colsample_bytree': Real(0.6, 1.0),\n",
    "    'gamma': Real(0, 0.3),\n",
    "    'reg_alpha': Real(0, 1.0),\n",
    "    'reg_lambda': Real(0, 10.0)\n",
    "}\n",
    "\n",
    "# Dividir los datos en conjuntos de entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, data_y, test_size=0.2, random_state=42)\n",
    "print(f'Número de entrenamiento: {X_train.shape}, Número de test: {X_test.shape}')\n",
    "\n",
    "# Crear el modelo base\n",
    "model = XGBClassifier(random_state=42)\n",
    "\n",
    "# Configurar la búsqueda bayesiana\n",
    "bayes_search = BayesSearchCV(\n",
    "    model,\n",
    "    param_space,\n",
    "    n_iter=50,  # Número de iteraciones para la optimización\n",
    "    scoring='accuracy',\n",
    "    cv=5,\n",
    "    verbose=1,\n",
    "    random_state=42,\n",
    "    n_jobs=-1  # Utilizar todos los núcleos disponibles\n",
    ")\n",
    "\n",
    "# Realizar la optimización bayesiana\n",
    "bayes_search.fit(X_train, y_train)\n",
    "\n",
    "# Obtener el mejor modelo\n",
    "best_model = bayes_search.best_estimator_\n",
    "\n",
    "# Realizar predicciones en el conjunto de prueba\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "# Calcular la precisión\n",
    "acc = accuracy_score(y_true=y_test, y_pred=y_pred)\n",
    "print(f'Precisión: {acc*100:.2f}%')\n",
    "\n",
    "# Imprimir los mejores hiperparámetros encontrados\n",
    "print(\"Mejores hiperparámetros encontrados:\")\n",
    "for param, value in bayes_search.best_params_.items():\n",
    "    print(f\"{param}: {value}\")\n",
    "\n",
    "# Calcular y mostrar el F1-score\n",
    "f1 = f1_score(y_true=y_test, y_pred=y_pred, average='weighted')\n",
    "print(f'F1-score: {f1:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from deap import creator, base, tools, algorithms\n",
    "\n",
    "def evaluar_cromosoma(individual, X, y, n_caracteristicas):\n",
    "    # Decodificar el cromosoma\n",
    "    selected_features = X.columns[np.array(individual, dtype=bool)]\n",
    "    \n",
    "    # Verificar restricciones\n",
    "    if len(selected_features) == 0:\n",
    "        return 1,  # Penalización máxima si no se selecciona ninguna característica\n",
    "    \n",
    "    # Entrenar el modelo\n",
    "    clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "    scores = cross_val_score(clf, X[selected_features], y, cv=5, scoring='accuracy')\n",
    "    \n",
    "    # Obtener medida de rendimiento (1 - sensibilidad para minimización)\n",
    "    rendimiento = 1 - np.mean(scores)\n",
    "    \n",
    "    # Castigar al cromosoma basado en la cantidad de características\n",
    "    penalizacion = len(selected_features) / n_caracteristicas\n",
    "    \n",
    "    # Devolver el valor de evaluación\n",
    "    return rendimiento + penalizacion,\n",
    "\n",
    "def seleccion_caracteristicas_genetico(df, target_column, n_generations=50, population_size=50):\n",
    "    X = df.drop(target_column, axis=1)\n",
    "    y = df[target_column]\n",
    "    n_caracteristicas = len(X.columns)\n",
    "\n",
    "    creator.create(\"FitnessMin\", base.Fitness, weights=(-1.0,))\n",
    "    creator.create(\"Individual\", list, fitness=creator.FitnessMin)\n",
    "\n",
    "    toolbox = base.Toolbox()\n",
    "    toolbox.register(\"attr_bool\", np.random.randint, 0, 2)\n",
    "    toolbox.register(\"individual\", tools.initRepeat, creator.Individual, toolbox.attr_bool, n=n_caracteristicas)\n",
    "    toolbox.register(\"population\", tools.initRepeat, list, toolbox.individual)\n",
    "\n",
    "    toolbox.register(\"evaluate\", evaluar_cromosoma, X=X, y=y, n_caracteristicas=n_caracteristicas)\n",
    "    toolbox.register(\"mate\", tools.cxTwoPoint)\n",
    "    toolbox.register(\"mutate\", tools.mutFlipBit, indpb=0.05)\n",
    "    toolbox.register(\"select\", tools.selTournament, tournsize=3)\n",
    "\n",
    "    population = toolbox.population(n=population_size)\n",
    "    \n",
    "    stats = tools.Statistics(lambda ind: ind.fitness.values)\n",
    "    stats.register(\"avg\", np.mean)\n",
    "    stats.register(\"min\", np.min)\n",
    "    \n",
    "    logbook = tools.Logbook()\n",
    "    hof = tools.HallOfFame(1)\n",
    "\n",
    "    for gen in range(n_generations):\n",
    "        offspring = algorithms.varAnd(population, toolbox, cxpb=0.5, mutpb=0.1 + (gen / n_generations) * 0.1)\n",
    "        fits = toolbox.map(toolbox.evaluate, offspring)\n",
    "        for fit, ind in zip(fits, offspring):\n",
    "            ind.fitness.values = fit\n",
    "        population = toolbox.select(offspring, k=len(population))\n",
    "        hof.update(population)\n",
    "        record = stats.compile(population)\n",
    "        logbook.record(gen=gen, **record)\n",
    "        print(f\"Generación {gen}: {record}\")\n",
    "\n",
    "    best_individual = hof[0]\n",
    "    selected_features = X.columns[np.array(best_individual, dtype=bool)].tolist()\n",
    "\n",
    "    return selected_features, logbook, hof"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from deap import creator, base, tools, algorithms\n",
    "\n",
    "def evaluar_cromosoma(individual, X, y, n_caracteristicas):\n",
    "    # Decodificar el cromosoma\n",
    "    selected_features = X.columns[np.array(individual, dtype=bool)]\n",
    "    \n",
    "    # Verificar restricciones\n",
    "    if len(selected_features) == 0:\n",
    "        return 1, \n",
    "    pipeline = Pipeline([\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('svm', SVC(kernel='rbf', random_state=42, probability=True))\n",
    "    ])\n",
    "    \n",
    "    # Entrenar y evaluar el modelo\n",
    "    scores = cross_val_score(pipeline, X[selected_features], y, cv=5, scoring='accuracy')\n",
    "    \n",
    "    # Obtener medida de rendimiento (1 - sensibilidad para minimización)\n",
    "    rendimiento = 1 - np.mean(scores)\n",
    "    \n",
    "    # Castigar al cromosoma basado en la cantidad de características\n",
    "    penalizacion = len(selected_features) / n_caracteristicas\n",
    "    \n",
    "    # Devolver el valor de evaluación\n",
    "    return rendimiento + penalizacion,\n",
    "\n",
    "def seleccion_caracteristicas_genetico(df, target_column, n_generations=50, population_size=50):\n",
    "    X = df.drop(target_column, axis=1)\n",
    "    y = df[target_column]\n",
    "    n_caracteristicas = len(X.columns)\n",
    "\n",
    "    creator.create(\"FitnessMin\", base.Fitness, weights=(-1.0,))\n",
    "    creator.create(\"Individual\", list, fitness=creator.FitnessMin)\n",
    "\n",
    "    toolbox = base.Toolbox()\n",
    "    toolbox.register(\"attr_bool\", np.random.randint, 0, 2)\n",
    "    toolbox.register(\"individual\", tools.initRepeat, creator.Individual, toolbox.attr_bool, n=n_caracteristicas)\n",
    "    toolbox.register(\"population\", tools.initRepeat, list, toolbox.individual)\n",
    "\n",
    "    toolbox.register(\"evaluate\", evaluar_cromosoma, X=X, y=y, n_caracteristicas=n_caracteristicas)\n",
    "    toolbox.register(\"mate\", tools.cxTwoPoint)\n",
    "    toolbox.register(\"mutate\", tools.mutFlipBit, indpb=0.05)\n",
    "    toolbox.register(\"select\", tools.selTournament, tournsize=3)\n",
    "\n",
    "    population = toolbox.population(n=population_size)\n",
    "    \n",
    "    stats = tools.Statistics(lambda ind: ind.fitness.values)\n",
    "    stats.register(\"avg\", np.mean)\n",
    "    stats.register(\"min\", np.min)\n",
    "    \n",
    "    logbook = tools.Logbook()\n",
    "    hof = tools.HallOfFame(1)\n",
    "\n",
    "    for gen in range(n_generations):\n",
    "        offspring = algorithms.varAnd(population, toolbox, cxpb=0.5, mutpb=0.1 + (gen / n_generations) * 0.1)\n",
    "        fits = toolbox.map(toolbox.evaluate, offspring)\n",
    "        for fit, ind in zip(fits, offspring):\n",
    "            ind.fitness.values = fit\n",
    "        population = toolbox.select(offspring, k=len(population))\n",
    "        hof.update(population)\n",
    "        record = stats.compile(population)\n",
    "        logbook.record(gen=gen, **record)\n",
    "        print(f\"Generación {gen}: {record}\")\n",
    "\n",
    "    best_individual = hof[0]\n",
    "    selected_features = X.columns[np.array(best_individual, dtype=bool)].tolist()\n",
    "\n",
    "    return selected_features, logbook, hof"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generación 0: {'avg': 0.8979024878419836, 'min': 0.8102286680437941}\n",
      "Generación 1: {'avg': 0.8523487593235494, 'min': 0.7767930235157126}\n",
      "Generación 2: {'avg': 0.8169522828951401, 'min': 0.7761575981744049}\n",
      "Generación 3: {'avg': 0.788686373288054, 'min': 0.7566257493988586}\n",
      "Generación 4: {'avg': 0.7721194423715432, 'min': 0.7559893146447767}\n",
      "Generación 5: {'avg': 0.7633448348708853, 'min': 0.7559893146447767}\n",
      "Generación 6: {'avg': 0.7522028660112693, 'min': 0.7132677215030155}\n",
      "Generación 7: {'avg': 0.7334303364589079, 'min': 0.69706513235925}\n"
     ]
    }
   ],
   "source": [
    "target_column = 'Valor'\n",
    "mejores_caracteristicas, logbook, hof = seleccion_caracteristicas_genetico(final, target_column)\n",
    "print(\"Mejores características seleccionadas:\", mejores_caracteristicas)\n",
    "print(\"Mejor fitness:\", hof[0].fitness.values[0])\n",
    "#calculando ga no corr mutb=0.05 a 0.15 y cpx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisión de 83.3616298811545\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, data_y, test_size=0.2)\n",
    "clf = make_pipeline(StandardScaler(), SVC(gamma='auto'))\n",
    "clf.fit(X, y)\n",
    "y_pred = clf.predict(X_test)\n",
    "acc = accuracy_score(y_true=y_test, y_pred=y_pred)\n",
    "print(f'Precisión de {acc*100}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfsAAAGwCAYAAACuFMx9AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuNSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/xnp5ZAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAzKElEQVR4nO3de3gU9b3H8c8mIfcbAZIQCQFEbspF0cYcFaWkBPCoHOixKmqgiBUJKigiKjdR06otFEVovRDpAe9CC7UoonKRqAXFC2KUgAJCghohJJjbzpw/IltXQHaZTZadeb+eZx7Z2d/MftcnT775fn+/mXGZpmkKAADYVliwAwAAAE2LZA8AgM2R7AEAsDmSPQAANkeyBwDA5kj2AADYHMkeAACbiwh2AFYYhqE9e/YoISFBLpcr2OEAAPxkmqYOHjyojIwMhYU1Xf1ZU1Ojuro6y+eJjIxUdHR0ACJqXiGd7Pfs2aPMzMxghwEAsGjXrl1q165dk5y7pqZGHbPiVbbPbflc6enp2rFjR8gl/JBO9gkJCZKk//nH5WoRFxnkaICmsW/AwWCHADSZBtVrvV72/D5vCnV1dSrb59aXmzooMeHEuweVBw1l9f1CdXV1JPvmdLh13yIukmQP24pwtQh2CEDT+eGG7c0xFRuf4FJ8wol/jqHQnS4O6WQPAICv3KYht4WnwbhNI3DBNDOSPQDAEQyZMnTi2d7KscHGpXcAANgclT0AwBEMGbLSiLd2dHCR7AEAjuA2TbnNE2/FWzk22GjjAwBgc1T2AABHcPICPZI9AMARDJlyOzTZ08YHAMDmqOwBAI5AGx8AAJtjNT4AALAtKnsAgCMYP2xWjg9VJHsAgCO4La7Gt3JssJHsAQCO4DZl8al3gYuluTFnDwCAzVHZAwAcgTl7AABszpBLbrksHR+qaOMDAGBzVPYAAEcwzMbNyvGhimQPAHAEt8U2vpVjg402PgAANkdlDwBwBCdX9iR7AIAjGKZLhmlhNb6FY4ONNj4AADZHZQ8AcATa+AAA2JxbYXJbaGi7AxhLcyPZAwAcwbQ4Z28yZw8AAE5WVPYAAEdgzh4AAJtzm2Fymxbm7EP4drm08QEAsDkqewCAIxhyybBQ4xoK3dKeyh4A4AiH5+ytbP4oLCzUOeeco4SEBKWmpmro0KEqKSnxGnPRRRfJ5XJ5bTfccIPXmJ07d+riiy9WbGysUlNTNWnSJDU0NPgVC5U9AABNYM2aNRo3bpzOOeccNTQ06M4779TAgQP1ySefKC4uzjNuzJgxuueeezyvY2NjPf92u926+OKLlZ6erg0bNmjv3r269tpr1aJFC91///0+x0KyBwA4gvUFev618VeuXOn1uqioSKmpqdq0aZP69evn2R8bG6v09PSjnuPVV1/VJ598otdee01paWnq06ePZs2apcmTJ2vGjBmKjIz0KRba+AAAR2ics7e2SVJlZaXXVltb69PnHzhwQJKUkpLitX/x4sVq3bq1zjjjDE2ZMkWHDh3yvFdcXKyePXsqLS3Nsy8vL0+VlZXasmWLz9+dyh4AAD9kZmZ6vZ4+fbpmzJjxs8cYhqFbbrlF5513ns444wzP/quuukpZWVnKyMjQhx9+qMmTJ6ukpEQvvfSSJKmsrMwr0UvyvC4rK/M5ZpI9AMARDIv3xj+8Gn/Xrl1KTEz07I+KijrusePGjdPHH3+s9evXe+2//vrrPf/u2bOn2rZtqwEDBqi0tFSnnnrqCcf6UyR7AIAjBGrOPjEx0SvZH09BQYFWrFihtWvXql27dj87Njs7W5K0bds2nXrqqUpPT9e7777rNaa8vFySjjnPfzTM2QMAHMFQmOXNH6ZpqqCgQEuXLtXrr7+ujh07HveYzZs3S5Latm0rScrJydFHH32kffv2ecasWrVKiYmJ6tGjh8+xUNkDANAExo0bpyVLlujvf/+7EhISPHPsSUlJiomJUWlpqZYsWaIhQ4aoVatW+vDDDzVhwgT169dPvXr1kiQNHDhQPXr00DXXXKMHHnhAZWVluvvuuzVu3Difpg8OI9kDABzBbbrktvCYWn+PnT9/vqTGG+f82MKFCzVy5EhFRkbqtdde05w5c1RdXa3MzEwNHz5cd999t2dseHi4VqxYobFjxyonJ0dxcXHKz8/3ui7fFyR7AIAjuC0u0HP7ebtc8zjX5WdmZmrNmjXHPU9WVpZefvllvz77p5izBwDA5qjsAQCOYJhhMiysxjf8vIPeyYRkDwBwhOZu459MaOMDAGBzVPYAAEcw5P+K+p8eH6pI9gAARziRG+P89PhQFbqRAwAAn1DZAwAcwfq98UO3PibZAwAc4cfPpD/R40MVyR4A4AhOruxDN3IAAOATKnsAgCNYv6lO6NbHJHsAgCMYpkuGlevsLRwbbKH7ZwoAAPAJlT0AwBEMi238UL6pDskeAOAI1p96F7rJPnQjBwAAPqGyBwA4glsuuS3cGMfKscFGsgcAOAJtfAAAYFtU9gAAR3DLWiveHbhQmh3JHgDgCE5u45PsAQCOwINwAACAbVHZAwAcwbT4PHuTS+8AADi50cYHAAC2RWUPAHAEJz/ilmQPAHAEt8Wn3lk5NthCN3IAAOATKnsAgCPQxgcAwOYMhcmw0NC2cmywhW7kAADAJ1T2AABHcJsuuS204q0cG2wkewCAIzBnDwCAzZkWn3pncgc9AABwsqKyBwA4glsuuS08zMbKscFGsgcAOIJhWpt3N8wABtPMaOMDAGBzVPYOV/1UrWrW1Mv9pSFFuRTZM1zxN0YpIivcM+bQsjrVvFqvhhK3zENSm1cTFJZw5F/HtW/Vq+rJWjVsM+SKkiLPjFDyH2Kb8+sAfru8oFyj7yzT0sdaa8H0U5SQ3KBrbivTWRdWKTWjTgcqIrRhZZKeeiBdhw6GH/+EOGkZFhfoWTk22Ej2Dlf3foNih0eqRfdwmW6pakGtvrvlkFoviZcrpjGhmzWmos6NUNS5EaqaX3vU89S8Ua/Kwu8Vf0O0Is8Ol9xSQ6nRnF8F8FuX3od08dUV2r4l2rMvJa1erdIa9Ng9bbXzs2iltqvTTb/frVZp9br3+g7BCxaWGXLJsDDvbuXYYDsp/kyZN2+eOnTooOjoaGVnZ+vdd98NdkiO0XJOnGIujlREp3C1OC1cSXdHyygzVf+p2zMm7oooxV0bpRZnHL2qMRtMHZxdo4SCaMUOi1RE+3BFdAxXdG6L5voagN+iY92a/MiXmjOpnQ4e+M/P9pclMZo1poPeWZWkvV9G6YO3ElT0h7bK/lWlwsJDeNIWjhb0ZP/ss89q4sSJmj59ut577z317t1beXl52rdvX7BDcySjqvG/YYm+/wXbUGLI+NqUwqRvr63S1/99UN9NqFZDqfv4BwNBUnD/V3p3daLeX5dw3LFxiW4dqgqT4Q7dyg7/uYOelS1UBT3Z/+lPf9KYMWM0atQo9ejRQwsWLFBsbKyefPLJYIfmOKZh6uCcGrXoFa6IU32fm3TvaWzXVz1Rq7hRUUp+KFZhCS5VjDsk4wCVEE4+F172nTr3/F5PFrY97tjElAZddUu5/vV/rZohMjSlw3P2VrZQFdTI6+rqtGnTJuXm5nr2hYWFKTc3V8XFxUeMr62tVWVlpdeGwDn4UI0atruVNCvGr+PMH6bm4/KjFN2/hVp0C1fi3TGSS6p5vb4JIgVOXJuMOo29Z4/+UNBe9bU//yswNt6tWYt2aOdn0frbH9ObKUIg8IK6QO+bb76R2+1WWlqa1/60tDR9+umnR4wvLCzUzJkzmys8R6l86HvVvtWglPlxCk/172/A8NaNra2Ijv85zhXpUniGS0Y5i/Rwcunc63u1bNOgea985tkXHiH1PLdal476Rv/doZcMw6WYOLfuW7Jd31eHaeboDnI3hG4LF40MWbw3fggv0Aup1fhTpkzRxIkTPa8rKyuVmZkZxIhCn2maOvjHGtWuaVDLR2MVnuF/syeiW7gUqcbL93r/cN4GU8ZeU2Hpodv2gj1tXhev6/t38dp36+xd2rUtWs/NayPDcCk2vjHR19e5NH1kx+N2ABAaTIur8U2S/Ylp3bq1wsPDVV5e7rW/vLxc6elHtsyioqIUFRXVXOE5wsGHalTzar2S/xArV6xL7m8bK/GwOJdc0Y0/2O5vDRnfmmrY3fheQ6lbrliXwtPCFJbkUlicS7FDI1X1eK3C0sIUnu5S9eI6SVL0L1mRj5PL99Xh+rLEe6qq5lCYDn7XuD823q37n96uqBhDD4zvoNh4t2LjGxebHvg2QoYRur/wnY6n3gVJZGSk+vbtq9WrV2vo0KGSJMMwtHr1ahUUFAQzNMf4/qXGOfXvxh3y2p94d7RiLo5sHLO0TtVP1Hne+27soSPGxI+PksKlypnfy6w11eL0cLV8JNavVf3AyaBzz+/VvW/jz3hRsfd04rW/6K7y3ZHBCAuwJOht/IkTJyo/P19nn322fvGLX2jOnDmqrq7WqFGjgh2aI6QVJx53TPx10Yq/Lvpnx7giXEq4KVoJN/38OOBkdPuvO3v+/WFxvPIyegcxGjQV7qAXRL/5zW/09ddfa9q0aSorK1OfPn20cuXKIxbtAQBgBW38ICsoKKBtDwBAEzkpkj0AAE3NyffGJ9kDABzByW380F1tAAAAfEJlDwBwBCdX9iR7AIAjODnZ08YHAMDmqOwBAI7g5MqeZA8AcART1i6fMwMXSrMj2QMAHMHJlT1z9gAA2ByVPQDAEZxc2ZPsAQCO4ORkTxsfAACbo7IHADiCkyt7kj0AwBFM0yXTQsK2cmyw0cYHAKAJFBYW6pxzzlFCQoJSU1M1dOhQlZSUeI2pqanRuHHj1KpVK8XHx2v48OEqLy/3GrNz505dfPHFio2NVWpqqiZNmqSGhga/YiHZAwAc4fDz7K1s/lizZo3GjRunt99+W6tWrVJ9fb0GDhyo6upqz5gJEyZo+fLlev7557VmzRrt2bNHw4YN87zvdrt18cUXq66uThs2bNBTTz2loqIiTZs2za9YaOMDAByhuefsV65c6fW6qKhIqamp2rRpk/r166cDBw7oiSee0JIlS/TLX/5SkrRw4UJ1795db7/9ts4991y9+uqr+uSTT/Taa68pLS1Nffr00axZszR58mTNmDFDkZGRPsVCZQ8AgB8qKyu9ttraWp+OO3DggCQpJSVFkrRp0ybV19crNzfXM6Zbt25q3769iouLJUnFxcXq2bOn0tLSPGPy8vJUWVmpLVu2+BwzyR4A4AiHF+hZ2SQpMzNTSUlJnq2wsPC4n20Yhm655Radd955OuOMMyRJZWVlioyMVHJystfYtLQ0lZWVecb8ONEffv/we76ijQ8AcIRAtfF37dqlxMREz/6oqKjjHjtu3Dh9/PHHWr9+/Ql/vhUkewCAIwTq0rvExESvZH88BQUFWrFihdauXat27dp59qenp6uurk779+/3qu7Ly8uVnp7uGfPuu+96ne/wav3DY3xBGx8AgCZgmqYKCgq0dOlSvf766+rYsaPX+3379lWLFi20evVqz76SkhLt3LlTOTk5kqScnBx99NFH2rdvn2fMqlWrlJiYqB49evgcC5U9AMARTIttfH+7AuPGjdOSJUv097//XQkJCZ459qSkJMXExCgpKUmjR4/WxIkTlZKSosTERI0fP145OTk699xzJUkDBw5Ujx49dM011+iBBx5QWVmZ7r77bo0bN86n6YPDSPYAAEcwJZmmteP9MX/+fEnSRRdd5LV/4cKFGjlypCRp9uzZCgsL0/Dhw1VbW6u8vDw9+uijnrHh4eFasWKFxo4dq5ycHMXFxSk/P1/33HOPX7GQ7AEAaAKmD39ZREdHa968eZo3b94xx2RlZenll1+2FAvJHgDgCIZccvl5F7yfHh+qSPYAAEfgQTgAAMC2qOwBAI5gmC65eJ49AAD2ZZoWV+NbODbYaOMDAGBzVPYAAEdw8gI9kj0AwBFI9gAA2JyTF+gxZw8AgM1R2QMAHMHJq/FJ9gAAR2hM9lbm7AMYTDOjjQ8AgM1R2QMAHIHV+AAA2Jwp/59J/9PjQxVtfAAAbI7KHgDgCLTxAQCwOwf38Un2AABnsFjZK4Qre+bsAQCwOSp7AIAjcAc9AABszskL9GjjAwBgc1T2AABnMF3WFtmFcGVPsgcAOIKT5+xp4wMAYHNU9gAAZ+CmOgAA2JuTV+P7lOz/8Y9/+HzCSy+99ISDAQAAgedTsh86dKhPJ3O5XHK73VbiAQCg6YRwK94Kn5K9YRhNHQcAAE3KyW18S6vxa2pqAhUHAABNywzAFqL8TvZut1uzZs3SKaecovj4eG3fvl2SNHXqVD3xxBMBDxAAAFjjd7K/7777VFRUpAceeECRkZGe/WeccYYef/zxgAYHAEDguAKwhSa/k/2iRYv017/+VSNGjFB4eLhnf+/evfXpp58GNDgAAAKGNr7vvvrqK3Xu3PmI/YZhqL6+PiBBAQCAwPE72ffo0UPr1q07Yv8LL7ygM888MyBBAQAQcA6u7P2+g960adOUn5+vr776SoZh6KWXXlJJSYkWLVqkFStWNEWMAABY5+Cn3vld2V922WVavny5XnvtNcXFxWnatGnaunWrli9frl/96ldNESMAALDghO6Nf8EFF2jVqlWBjgUAgCbj5EfcnvCDcDZu3KitW7dKapzH79u3b8CCAgAg4Hjqne92796tK6+8Um+99ZaSk5MlSfv379d//dd/6ZlnnlG7du0CHSMAALDA7zn76667TvX19dq6dasqKipUUVGhrVu3yjAMXXfddU0RIwAA1h1eoGdlC1F+V/Zr1qzRhg0b1LVrV8++rl276uGHH9YFF1wQ0OAAAAgUl9m4WTk+VPmd7DMzM4968xy3262MjIyABAUAQMA5eM7e7zb+gw8+qPHjx2vjxo2efRs3btTNN9+shx56KKDBAQAA63yq7Fu2bCmX6z9zFdXV1crOzlZEROPhDQ0NioiI0G9/+1sNHTq0SQIFAMASB99Ux6dkP2fOnCYOAwCAJubgNr5PyT4/P7+p4wAAAE3khG+qI0k1NTWqq6vz2peYmGgpIAAAmoSDK3u/F+hVV1eroKBAqampiouLU8uWLb02AABOSg5+6p3fyf7222/X66+/rvnz5ysqKkqPP/64Zs6cqYyMDC1atKgpYgQAABb43cZfvny5Fi1apIsuukijRo3SBRdcoM6dOysrK0uLFy/WiBEjmiJOAACscfBqfL8r+4qKCnXq1ElS4/x8RUWFJOn888/X2rVrAxsdAAABcvgOela2UOV3su/UqZN27NghSerWrZuee+45SY0V/+EH4wAAgJOH38l+1KhR+uCDDyRJd9xxh+bNm6fo6GhNmDBBkyZNCniAAAAEhIMX6Pk9Zz9hwgTPv3Nzc/Xpp59q06ZN6ty5s3r16hXQ4AAAgHWWrrOXpKysLGVlZQUiFgAAmoxLFp96F7BImp9PyX7u3Lk+n/Cmm2464WAAAEDg+ZTsZ8+e7dPJXC5XUJL9t7+JUkRYZLN/LtAcXtmzOdghAE2m8qChll2a6cMcfOmdT8n+8Op7AABCFrfLBQAAdmV5gR4AACHBwZU9yR4A4AhW74LnqDvoAQCA0EJlDwBwBge38U+osl+3bp2uvvpq5eTk6KuvvpIk/e1vf9P69esDGhwAAAHj4Nvl+p3sX3zxReXl5SkmJkbvv/++amtrJUkHDhzQ/fffH/AAAQCANX4n+3vvvVcLFizQY489phYtWnj2n3feeXrvvfcCGhwAAIHCI279UFJSon79+h2xPykpSfv37w9ETAAABN7hO+hZ2fywdu1aXXLJJcrIyJDL5dKyZcu83h85cqRcLpfXNmjQIK8xFRUVGjFihBITE5WcnKzRo0erqqrK76/ud7JPT0/Xtm3bjti/fv16derUye8AAABoFs08Z19dXa3evXtr3rx5xxwzaNAg7d2717M9/fTTXu+PGDFCW7Zs0apVq7RixQqtXbtW119/vX+B6ARW448ZM0Y333yznnzySblcLu3Zs0fFxcW67bbbNHXqVL8DAAAglFRWVnq9joqKUlRU1BHjBg8erMGDB//suaKiopSenn7U97Zu3aqVK1fq3//+t84++2xJ0sMPP6whQ4booYceUkZGhs8x+13Z33HHHbrqqqs0YMAAVVVVqV+/frruuuv0u9/9TuPHj/f3dAAANItAzdlnZmYqKSnJsxUWFp5wTG+++aZSU1PVtWtXjR07Vt9++63nveLiYiUnJ3sSvSTl5uYqLCxM77zzjl+f43dl73K5dNddd2nSpEnatm2bqqqq1KNHD8XHx/t7KgAAmk+ArrPftWuXEhMTPbuPVtX7YtCgQRo2bJg6duyo0tJS3XnnnRo8eLCKi4sVHh6usrIypaameh0TERGhlJQUlZWV+fVZJ3xTncjISPXo0eNEDwcAICQlJiZ6JfsTdcUVV3j+3bNnT/Xq1Uunnnqq3nzzTQ0YMMDy+X/M72Tfv39/uVzHXpH4+uuvWwoIAIAmYfXyuSa+9K5Tp05q3bq1tm3bpgEDBig9PV379u3zGtPQ0KCKiopjzvMfi9/Jvk+fPl6v6+vrtXnzZn388cfKz8/393QAADSPk/x2ubt379a3336rtm3bSpJycnK0f/9+bdq0SX379pXUWFAbhqHs7Gy/zu13sp89e/ZR98+YMeOErv0DAMCOqqqqvC5V37FjhzZv3qyUlBSlpKRo5syZGj58uNLT01VaWqrbb79dnTt3Vl5eniSpe/fuGjRokMaMGaMFCxaovr5eBQUFuuKKK/xaiS8F8Kl3V199tZ588slAnQ4AgMBq5uvsN27cqDPPPFNnnnmmJGnixIk688wzNW3aNIWHh+vDDz/UpZdeqi5dumj06NHq27ev1q1b57Xgb/HixerWrZsGDBigIUOG6Pzzz9df//pXv796wJ56V1xcrOjo6ECdDgCAgGru59lfdNFFMs1jH/TKK68c9xwpKSlasmSJfx98FH4n+2HDhnm9Nk1Te/fu1caNG7mpDgAAJyG/k31SUpLX67CwMHXt2lX33HOPBg4cGLDAAABAYPiV7N1ut0aNGqWePXuqZcuWTRUTAACBd5Kvxm9Kfi3QCw8P18CBA3m6HQAg5PCIWz+cccYZ2r59e1PEAgAAmoDfyf7ee+/VbbfdphUrVmjv3r2qrKz02gAAOGk102V3Jxuf5+zvuece3XrrrRoyZIgk6dJLL/W6ba5pmnK5XHK73YGPEgAAqxw8Z+9zsp85c6ZuuOEGvfHGG00ZDwAACDCfk/3hGwNceOGFTRYMAABNpblvqnMy8evSu5972h0AACc12vi+6dKly3ETfkVFhaWAAABAYPmV7GfOnHnEHfQAAAgFtPF9dMUVVyg1NbWpYgEAoOk4uI3v83X2zNcDABCa/F6NDwBASHJwZe9zsjcMoynjAACgSTFnDwCA3Tm4svf73vgAACC0UNkDAJzBwZU9yR4A4AhOnrOnjQ8AgM1R2QMAnIE2PgAA9kYbHwAA2BaVPQDAGWjjAwBgcw5O9rTxAQCwOSp7AIAjuH7YrBwfqkj2AABncHAbn2QPAHAELr0DAAC2RWUPAHAG2vgAADhACCdsK2jjAwBgc1T2AABHcPICPZI9AMAZHDxnTxsfAACbo7IHADgCbXwAAOyONj4AALArKnsAgCPQxgcAwO4c3MYn2QMAnMHByZ45ewAAbI7KHgDgCMzZAwBgd7TxAQCAXVHZAwAcwWWacpknXp5bOTbYSPYAAGegjQ8AAOyKyh4A4AisxgcAwO5o4wMAALuisgcAOAJtfAAA7M7BbXySPQDAEZxc2TNnDwCAzVHZAwCcgTY+AAD2F8qteCto4wMAYHNU9gAAZzDNxs3K8SGKZA8AcARW4wMAANuisgcAOAOr8QEAsDeX0bhZOT5U0cYHAMDmqOxxhBE3lGrE2B1e+3btiNXvhv6X53W3XvuVP75UXXsekOF2aXtJgu4ee6bqasObO1zgZz3zcKreejlZu7ZFKTLaUI+zD2n0XXuU2blWklS2K1L52T2Oeuxdf9mhfpcckCTlZfQ54v0pj36hi4bub6rQEWi08QFvX2yL013Xn+V57Xa7PP/u1mu/Zj36vp57sqPm/76r3A0udepaJcNwHe1UQFB9WByvS0Z+oy59DsndIBX9vq3uvPJUPbbmU0XHGmqTUaenN3/sdczL/9dKL8xP1Tm/POi1/9bZO3V2/0rP6/hEd7N8BwQGq/GDZO3atbrkkkuUkZEhl8ulZcuWBTMc/Ii7waXvvo3ybJX7Iz3vXT/pM/3j6fZ6/skO2lkar6++jNO6V9PUUM+sEE4+9y/ZroG/qVCHrjU69fQa3Tpnp/Z9FanPP4yRJIWHSympDV7bhn8lqd8l+xUT5z1JG5/o9hoXGR3Cv/2d6PB19lY2Pxwvx5mmqWnTpqlt27aKiYlRbm6uPv/8c68xFRUVGjFihBITE5WcnKzRo0erqqrK768e1N/O1dXV6t27t+bNmxfMMHAUp2Qd0t9WrdUT/3xLk+7/WG3SayRJSSl16tarUvsrWuihp/6txa+v1R+e2KgeZ+4PbsCAj6orG6eaEpKPXpV//mGMSrfEKu/Kb49475G7TtH/nn6Gxg85Ta88nRLK91hBMzhejnvggQc0d+5cLViwQO+8847i4uKUl5enmpoaz5gRI0Zoy5YtWrVqlVasWKG1a9fq+uuv9zuWoLbxBw8erMGDB/s8vra2VrW1tZ7XlZWVPzMaJ6rkoyT9aerp2v1FrFLa1Omq323Xgws3auzwc5V+yveSpBE37NATfzpNpSXxGvDfe1X4100aOzxHe3bGBjl64NgMQ1ow/RSdfk6VOnSrOeqYlU+3UvvTanT6OYe89l87aa/6nFelqBhDm9Yk6OE72+n76jANve6b5ggdAdDcbfyfy3GmaWrOnDm6++67ddlll0mSFi1apLS0NC1btkxXXHGFtm7dqpUrV+rf//63zj77bEnSww8/rCFDhuihhx5SRkaGz7GEVN+1sLBQSUlJni0zMzPYIdnSxrdaa/2qNH3xeYLe29BK0wv6KC6hXhfklSssrPGn/V8vnKJVf8/Q9k8T9dhDXbX7izgNHLonyJEDP++RO9vpy09jNGX+l0d9v/Z7l95Y2vKoVf2ICeU6/RfV6tzze/2mYJ/+d+w+PT8/talDRiCZAdjUWGj+ePtxEeqrHTt2qKysTLm5uZ59SUlJys7OVnFxsSSpuLhYycnJnkQvSbm5uQoLC9M777zj1+eFVLKfMmWKDhw44Nl27doV7JAcofpgC331ZZwyMr9XxTdRkqSd2+O8xuzaEedp9QMno0fuPEXvrErUAy9sU5uM+qOOWffPZNV+71Lu/1Yc93zdzjqkb/ZGqq6WhalOk5mZ6VV4FhYW+n2OsrIySVJaWprX/rS0NM97ZWVlSk31/oMyIiJCKSkpnjG+CqnV+FFRUYqKigp2GI4THdOgtpmH9Po/01X+VbS+2Reldh28W5ynZFVr4/rWQYoQODbTlObddYo2rEzSgy9sU3r7umOOfeXpVjp3YKWSWx1/lX3plhjFJzcoMoqJ+1ARqDb+rl27lJiY6NkfCnkppJI9msfoiZ/pnTVttG9vtFq1qdXVY7fLcLv05r/SJbn0YlGWrh5bqu0l8dpekqDcS/eqXYdDuu9W3+ePgObyyJ3t9MbSlpqxcLti4g1V7Gv8tReX4FZUzH9+83+1I1IfvR2nWf+3/YhzvP1qor77OkLd+x5SiyhD761N0DNzU/XrG75utu+BAAjQU+8SExO9kv2JSE9PlySVl5erbdu2nv3l5eXq06ePZ8y+ffu8jmtoaFBFRYXneF+R7HGE1mm1mvz7j5SYXK8D30Vqy/vJmnDNOar8rvHyu78vbq/IKEPXT/pMCUn12l6SoLtuOEtlu1mch5PPiqcaO06Thp/mtf/W2Ts18Df/ade/8kwrtW5br74Xel9bL0nhLUwtL2qtv8yIkmlKGR3q9LsZezR4xJFz+4AvOnbsqPT0dK1evdqT3CsrK/XOO+9o7NixkqScnBzt379fmzZtUt++fSVJr7/+ugzDUHZ2tl+fF9RkX1VVpW3btnle79ixQ5s3b1ZKSorat28fxMic7Q+Tex53zPNPdtDzT3Zo+mAAi17Zs9mncb+dsle/nbL3qO+d0/+gzul/5B8BCC3NvRr/eDnulltu0b333qvTTjtNHTt21NSpU5WRkaGhQ4dKkrp3765BgwZpzJgxWrBggerr61VQUKArrrjCr5X4UpCT/caNG9W/f3/P64kTJ0qS8vPzVVRUFKSoAAC21My3yz1ejrv99ttVXV2t66+/Xvv379f555+vlStXKjo62nPM4sWLVVBQoAEDBigsLEzDhw/X3Llz/Q7dZZqhe1uIyspKJSUlaUDr0YoIizz+AUAIevmDVcEOAWgylQcNteyyXQcOHLA8D37Mz/ghV+QMukcRLaKPf8AxNNTXqHjltCaNtakwZw8AcAQn3xufZA8AcAbDbNysHB+iSPYAAGdw8CNuQ+oOegAAwH9U9gAAR3DJ4px9wCJpfiR7AIAzBOgOeqGINj4AADZHZQ8AcAQuvQMAwO5YjQ8AAOyKyh4A4Agu05TLwiI7K8cGG8keAOAMxg+bleNDFG18AABsjsoeAOAItPEBALA7B6/GJ9kDAJyBO+gBAAC7orIHADgCd9ADAMDuaOMDAAC7orIHADiCy2jcrBwfqkj2AABnoI0PAADsisoeAOAM3FQHAAB7c/LtcmnjAwBgc1T2AABncPACPZI9AMAZTFl7Jn3o5nqSPQDAGZizBwAAtkVlDwBwBlMW5+wDFkmzI9kDAJzBwQv0aOMDAGBzVPYAAGcwJLksHh+iSPYAAEdgNT4AALAtKnsAgDM4eIEeyR4A4AwOTva08QEAsDkqewCAMzi4sifZAwCcgUvvAACwNy69AwAAtkVlDwBwBubsAQCwOcOUXBYSthG6yZ42PgAANkdlDwBwBtr4AADYncVkr9BN9rTxAQCwOSp7AIAz0MYHAMDmDFOWWvGsxgcAACcrKnsAgDOYRuNm5fgQRbIHADgDc/YAANgcc/YAAMCuqOwBAM5AGx8AAJszZTHZByySZkcbHwAAm6OyBwA4A218AABszjAkWbhW3gjd6+xp4wMAYHNU9gAAZ6CNDwCAzTk42dPGBwDA5qjsAQDO4ODb5ZLsAQCOYJqGTAtPrrNybLCR7AEAzmCa1qpz5uwBAMCPzZgxQy6Xy2vr1q2b5/2amhqNGzdOrVq1Unx8vIYPH67y8vImiYVkDwBwhsOr8a1sfjr99NO1d+9ez7Z+/XrPexMmTNDy5cv1/PPPa82aNdqzZ4+GDRsWyG/sQRsfAOAMhiG5LMy7n8CcfUREhNLT04/Yf+DAAT3xxBNasmSJfvnLX0qSFi5cqO7du+vtt9/Wueeee+JxHgWVPQAAfqisrPTaamtrjzn2888/V0ZGhjp16qQRI0Zo586dkqRNmzapvr5eubm5nrHdunVT+/btVVxcHPCYSfYAAGcIUBs/MzNTSUlJnq2wsPCoH5edna2ioiKtXLlS8+fP144dO3TBBRfo4MGDKisrU2RkpJKTk72OSUtLU1lZWcC/Om18AIAjmIYh00Ib//Cld7t27VJiYqJnf1RU1FHHDx482PPvXr16KTs7W1lZWXruuecUExNzwnGcCCp7AAD8kJiY6LUdK9n/VHJysrp06aJt27YpPT1ddXV12r9/v9eY8vLyo87xW0WyBwA4QxBW4/9YVVWVSktL1bZtW/Xt21ctWrTQ6tWrPe+XlJRo586dysnJsfpNj0AbHwDgDIYpuZrvpjq33XabLrnkEmVlZWnPnj2aPn26wsPDdeWVVyopKUmjR4/WxIkTlZKSosTERI0fP145OTkBX4kvkewBAGgSu3fv1pVXXqlvv/1Wbdq00fnnn6+3335bbdq0kSTNnj1bYWFhGj58uGpra5WXl6dHH320SWIh2QMAnME0JVm5zt6/yv6ZZ5752fejo6M1b948zZs378Rj8hHJHgDgCKZhyrTQxjdD+N74JHsAgDOYhqxV9qH71DtW4wMAYHNU9gAAR6CNDwCA3Tm4jR/Syf7wX1kNRl2QIwGaTuXB0P0FAxxPZVXjz3dzVM0NqpcsfEyD6gMXTDML6WR/8OBBSdKair8FORKg6bTsEuwIgKZ38OBBJSUlNcm5IyMjlZ6ervVlL1s+V3p6uiIjIwMQVfNymSE8CWEYhvbs2aOEhAS5XK5gh+MIlZWVyszMPOJBEIAd8PPd/EzT1MGDB5WRkaGwsKZbM15TU6O6Outd4MjISEVHRwcgouYV0pV9WFiY2rVrF+wwHOnwAyAAO+Lnu3k1VUX/Y9HR0SGZpAOFS+8AALA5kj0AADZHsodfoqKiNH36dJ+f3wyEEn6+YVchvUAPAAAcH5U9AAA2R7IHAMDmSPYAANgcyR4AAJsj2cNn8+bNU4cOHRQdHa3s7Gy9++67wQ4JCIi1a9fqkksuUUZGhlwul5YtWxbskICAItnDJ88++6wmTpyo6dOn67333lPv3r2Vl5enffv2BTs0wLLq6mr17t1b8+bNC3YoQJPg0jv4JDs7W+ecc44eeeQRSY3PJcjMzNT48eN1xx13BDk6IHBcLpeWLl2qoUOHBjsUIGCo7HFcdXV12rRpk3Jzcz37wsLClJubq+Li4iBGBgDwBckex/XNN9/I7XYrLS3Na39aWprKysqCFBUAwFckewAAbI5kj+Nq3bq1wsPDVV5e7rW/vLxc6enpQYoKAOArkj2OKzIyUn379tXq1as9+wzD0OrVq5WTkxPEyAAAvogIdgAIDRMnTlR+fr7OPvts/eIXv9CcOXNUXV2tUaNGBTs0wLKqqipt27bN83rHjh3avHmzUlJS1L59+yBGBgQGl97BZ4888ogefPBBlZWVqU+fPpo7d66ys7ODHRZg2Ztvvqn+/fsfsT8/P19FRUXNHxAQYCR7AABsjjl7AABsjmQPAIDNkewBALA5kj0AADZHsgcAwOZI9gAA2BzJHgAAmyPZAwBgcyR7wKKRI0dq6NChntcXXXSRbrnllmaP480335TL5dL+/fuPOcblcmnZsmU+n3PGjBnq06ePpbi++OILuVwubd682dJ5AJw4kj1saeTIkXK5XHK5XIqMjFTnzp11zz33qKGhock/+6WXXtKsWbN8GutLggYAq3gQDmxr0KBBWrhwoWpra/Xyyy9r3LhxatGihaZMmXLE2Lq6OkVGRgbkc1NSUgJyHgAIFCp72FZUVJTS09OVlZWlsWPHKjc3V//4xz8k/af1ft999ykjI0Ndu3aVJO3atUuXX365kpOTlZKSossuu0xffPGF55xut1sTJ05UcnKyWrVqpdtvv10/fbzET9v4tbW1mjx5sjIzMxUVFaXOnTvriSee0BdffOF5+ErLli3lcrk0cuRISY2PEC4sLFTHjh0VExOj3r1764UXXvD6nJdfflldunRRTEyM+vfv7xWnryZPnqwuXbooNjZWnTp10tSpU1VfX3/EuL/85S/KzMxUbGysLr/8ch04cMDr/ccff1zdu3dXdHS0unXrpkcffdTvWAA0HZI9HCMmJkZ1dXWe16tXr1ZJSYlWrVqlFStWqL6+Xnl5eUpISNC6dev01ltvKT4+XoMGDfIc98c//lFFRUV68skntX79elVUVGjp0qU/+7nXXnutnn76ac2dO1dbt27VX/7yF8XHxyszM1MvvviiJKmkpER79+7Vn//8Z0lSYWGhFi1apAULFmjLli2aMGGCrr76aq1Zs0ZS4x8lw4YN0yWXXKLNmzfruuuu0x133OH3/5OEhAQVFRXpk08+0Z///Gc99thjmj17tteYbdu26bnnntPy5cu1cuVKvf/++7rxxhs97y9evFjTpk3Tfffdp61bt+r+++/X1KlT9dRTT/kdD4AmYgI2lJ+fb1522WWmaZqmYRjmqlWrzKioKPO2227zvJ+WlmbW1tZ6jvnb3/5mdu3a1TQMw7OvtrbWjImJMV955RXTNE2zbdu25gMPPOB5v76+3mzXrp3ns0zTNC+88ELz5ptvNk3TNEtKSkxJ5qpVq44a5xtvvGFKMr/77jvPvpqaGjM2NtbcsGGD19jRo0ebV155pWmapjllyhSzR48eXu9Pnjz5iHP9lCRz6dKlx3z/wQcfNPv27et5PX36dDM8PNzcvXu3Z9+//vUvMywszNy7d69pmqZ56qmnmkuWLPE6z6xZs8ycnBzTNE1zx44dpiTz/fffP+bnAmhazNnDtlasWKH4+HjV19fLMAxdddVVmjFjhuf9nj17es3Tf/DBB9q2bZsSEhK8zlNTU6PS0lIdOHBAe/fuVXZ2tue9iIgInX322Ue08g/bvHmzwsPDdeGFF/oc97Zt23To0CH96le/8tpfV1enM888U5K0detWrzgkKScnx+fPOOzZZ5/V3LlzVVpaqqqqKjU0NCgxMdFrTPv27XXKKad4fY5hGCopKVFCQoJKS0s1evRojRkzxjOmoaFBSUlJfscDoGmQ7GFb/fv31/z58xUZGamMjAxFRHj/uMfFxXm9rqqqUt++fbV48eIjztWmTZsTiiEmJsbvY6qqqiRJ//znP72SrNS4DiFQiouLNWLECM2cOVN5eXlKSkrSM888oz/+8Y9+x/rYY48d8cdHeHh4wGIFYA3JHrYVFxenzp07+zz+rLPO0rPPPqvU1NQjqtvD2rZtq3feeUf9+vWT1FjBbtq0SWedddZRx/fs2VOGYWjNmjXKzc094v3DnQW32+3Z16NHD0VFRWnnzp3H7Ah0797ds9jwsLfffvv4X/JHNmzYoKysLN11112efV9++eUR43bu3Kk9e/YoIyPD8zlhYWHq2rWr0tLSlJGRoe3bt2vEiBF+fT6A5sMCPeAHI0aMUOvWrXXZZZdp3bp12rFjh958803ddNNN2r17tyTp5ptv1u9//3stW7ZMn376qW688cafvUa+Q4cOys/P129/+1stW7bMc87nnntOkpSVlSWXy6UVK1bo66+/VlVVlRISEnTbbbdpwoQJeuqpp1RaWqr33ntPDz/8sGfR2w033KDPP/9ckyZNUklJiZYsWaKioiK/vu9pp52mnTt36plnnlFpaanmzp171MWG0dHRys/P1wcffKB169bppptu0uWXX6709HRJ0syZM1VYWKi5c+fqs88+00cffaSFCxfqT3/6k1/xAGg6JHvgB7GxsVq7dq3at2+vYcOGqXv37ho9erRqamo8lf6tt96qa665Rvn5+crJyVFCQoL+53/+52fPO3/+fP3617/WjTfeqG7dumnMmDGqrq6WJJ1yyimaOXOm7rjjDqWlpamgoECSNGvWLE2dOlWFhYXq3r27Bg0apH/+85/q2LGjpMZ59BdffFHLli1T7969tWDBAt1///1+fd9LL71UEyZMUEFBgfr06aMNGzZo6tSpR4zr3Lmzhg0bpiFDhmjgwIHq1auX16V11113nR5//HEtXLhQPXv21IUXXqiioiJPrACCz2Uea2URAACwBSp7AABsjmQPAIDNkewBALA5kj0AADZHsgcAwOZI9gAA2BzJHgAAmyPZAwBgcyR7AABsjmQPAIDNkewBALC5/wdTyE4F/gKbzAAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "predictions = clf.predict(X_test)\n",
    "cm = confusion_matrix(y_test, predictions)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "disp.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, data_y, test_size=0.2, random_state=42)\n",
    "\n",
    "pipeline = make_pipeline(\n",
    "    SelectKBest(f_classif, k='all'),  \n",
    "    StandardScaler(),\n",
    "    SVC(random_state=42)\n",
    ")\n",
    "\n",
    "\n",
    "param_grid = {\n",
    "    'selectkbest__k': [5, 10, 'all'],  \n",
    "    'svc__C': [0.1, 1, 10, 100],\n",
    "    'svc__gamma': ['scale', 'auto', 0.1, 1],\n",
    "    'svc__kernel': ['rbf', 'poly', 'sigmoid']\n",
    "}\n",
    "\n",
    "\n",
    "grid_search = GridSearchCV(pipeline, param_grid, cv=5, scoring='accuracy', n_jobs=-1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "print(f'Precisión mejorada: {acc*100:.2f}%')\n",
    "\n",
    "print(\"Mejores parámetros encontrados:\")\n",
    "print(grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "geotiff",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
