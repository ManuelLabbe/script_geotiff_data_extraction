{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def cart_feature_selection(df, target_column, n_features=5):\n",
    "    X = df.drop(target_column, axis=1)\n",
    "    y = df[target_column]\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    \n",
    "    cart = RandomForestClassifier(random_state=42)\n",
    "    #cart = XGBClassifier(random_state=42)\n",
    "    cart.fit(X_train, y_train)\n",
    "    \n",
    "    feature_importance = pd.DataFrame({\n",
    "        'feature': X.columns,\n",
    "        'importance': cart.feature_importances_\n",
    "    }).sort_values('importance', ascending=False)\n",
    "    \n",
    "    selected_features = feature_importance['feature'][:n_features].tolist()\n",
    "    \n",
    "    return selected_features\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from deap import creator, base, tools, algorithms\n",
    "\n",
    "def genetic_feature_selection(df, target_column, n_generations=50, population_size=50):\n",
    "    X = df.drop(target_column, axis=1)\n",
    "    y = df[target_column]\n",
    "\n",
    "    creator.create(\"FitnessMax\", base.Fitness, weights=(1.0,))\n",
    "    creator.create(\"Individual\", list, fitness=creator.FitnessMax)\n",
    "\n",
    "    toolbox = base.Toolbox()\n",
    "    toolbox.register(\"attr_bool\", np.random.randint, 0, 2)\n",
    "    toolbox.register(\"individual\", tools.initRepeat, creator.Individual, toolbox.attr_bool, n=len(X.columns))\n",
    "    toolbox.register(\"population\", tools.initRepeat, list, toolbox.individual)\n",
    "\n",
    "    def evaluate(individual):\n",
    "        selected_features = X.columns[np.array(individual, dtype=bool)]\n",
    "        if len(selected_features) == 0:\n",
    "            return 0,\n",
    "        clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "        scores = cross_val_score(clf, X[selected_features], y, cv=5)\n",
    "        return np.mean(scores),\n",
    "\n",
    "    toolbox.register(\"evaluate\", evaluate)\n",
    "    toolbox.register(\"mate\", tools.cxTwoPoint)\n",
    "    toolbox.register(\"mutate\", tools.mutFlipBit, indpb=0.05)\n",
    "    toolbox.register(\"select\", tools.selTournament, tournsize=3)\n",
    "\n",
    "    population = toolbox.population(n=population_size)\n",
    "    algorithms.eaSimple(population, toolbox, cxpb=0.5, mutpb=0.2, ngen=n_generations, verbose=False)\n",
    "\n",
    "    best_individual = tools.selBest(population, k=1)[0]\n",
    "    selected_features = X.columns[np.array(best_individual, dtype=bool)].tolist()\n",
    "\n",
    "    return selected_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_1 = pd.read_csv('New_DB_2.csv')\n",
    "db_0 = pd.read_csv('New_DB_0.csv')\n",
    "db_1 = db_1.drop(columns='Valor')\n",
    "db_0 = db_0.drop(columns='Valor')\n",
    "db_1['Fecha Evento'] = pd.to_datetime(db_1['Fecha Evento'], format='%d/%m/%Y', errors='coerce')\n",
    "db_0['Fecha Evento'] = pd.to_datetime(db_0['Fecha Evento'], format='%d/%m/%Y', errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw = pd.read_csv('data_processed.csv')\n",
    "raw = raw.drop_duplicates(subset=['Latitud', 'Longitud', 'Fecha Evento'])\n",
    "raw = raw.reset_index()\n",
    "raw['Fecha Evento'] = pd.to_datetime(raw['Fecha Evento'], format='%d/%m/%Y', errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((602, 137), (602, 137))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_1 = pd.read_csv('test_data_1')\n",
    "df_0 = pd.read_csv('test_data_0_2')\n",
    "df_1 = df_1.drop(columns=['Unnamed: 0.1', 'Unnamed: 0'])\n",
    "df_0 = df_0.drop(columns=['Unnamed: 0'])\n",
    "df_1['Valor'] = 1\n",
    "df_0['Valor'] = 0\n",
    "df_1['Fecha Evento'] = raw['Fecha Evento']\n",
    "df_0['Fecha Evento'] = raw['Fecha Evento']\n",
    "#df_1['Fecha Evento'] = pd.to_datetime(df_1['Fecha Evento'], format='%d/%m/%Y', errors='coerce')\n",
    "#df_0['Fecha Evento'] = pd.to_datetime(df_0['Fecha Evento'], format='%d/%m/%Y', errors='coerce')\n",
    "df_1.shape, df_0.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_0 = pd.merge(df_0 , db_0, on=['Latitud', 'Longitud', 'Fecha Evento'], how='inner')\n",
    "df_1 = pd.merge(df_1 , db_1, on=['Latitud', 'Longitud', 'Fecha Evento'], how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1 = df_1.drop(columns=['valor_humedad_suelo2','valor_humedad_suelo3', 'valor_humedad_suelo4',\n",
    "       'Tipo Remoción en masa', 'Unnamed: 0','Región', 'Comuna', 'Factor desencadenante',\n",
    "       'Sistema Georeferencia', 'Cota (m.s.n.m)', 'Fecha Evento'])\n",
    "df_0 = df_0.drop(columns=['valor_humedad_suelo2','valor_humedad_suelo3', 'valor_humedad_suelo4',\n",
    "       'Tipo Remoción en masa', 'Unnamed: 0','Región', 'Comuna', 'Factor desencadenante',\n",
    "       'Sistema Georeferencia', 'Cota (m.s.n.m)', 'Fecha Evento'])\n",
    "df_1 = df_1.fillna(df_1.mean())\n",
    "df_0 = df_0.fillna(df_0.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1070, 136), (1070,))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.concat([df_0,df_1])\n",
    "df = df.drop(columns=['Longitud', 'Latitud'])\n",
    "df_x = df.drop(columns='Valor')\n",
    "df_y = df.Valor\n",
    "df_x.shape, df_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Características seleccionadas por CART: ['PIRange_Bulkd.5-15cm.tif', 'PIRange_Clay.0-5cm.tif', 'ksat_30-60cm.tif', 'valor_humedad_suelo1', 'PIRange_Sand.5-15cm.tif']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ivo\\.conda\\envs\\geotiff\\lib\\site-packages\\deap\\creator.py:185: RuntimeWarning: A class named 'FitnessMax' has already been created and it will be overwritten. Consider deleting previous creation of that class or rename it.\n",
      "  warnings.warn(\"A class named '{0}' has already been created and it \"\n",
      "c:\\Users\\ivo\\.conda\\envs\\geotiff\\lib\\site-packages\\deap\\creator.py:185: RuntimeWarning: A class named 'Individual' has already been created and it will be overwritten. Consider deleting previous creation of that class or rename it.\n",
      "  warnings.warn(\"A class named '{0}' has already been created and it \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Características seleccionadas por el algoritmo genético: ['PIRange_Bulkd.0-5cm.tif', 'PIRange_Bulkd.100-200cm.tif', 'PIRange_Bulkd.15-30cm.tif', 'PIRange_Bulkd.30-60cm.tif', 'PIRange_Bulkd.60-100cm.tif', 'PIRange_Clay.0-5cm.tif', 'PIRange_Clay.15-30cm.tif', 'PIRange_Clay.30-60cm.tif', 'PIRange_Sand.0-5cm.tif', 'PIRange_Sand.100-200cm.tif', 'PIRange_Sand.60-100cm.tif', 'alpha_30-60cm.tif', 'alpha_60-100cm.tif', 'AvMoist.0-5cm.tif', 'AWC_0-5cm.tif', 'AWC_100-200cm.tif', 'AWC_5-15cm.tif', 'AWC_60-100cm.tif', 'FC.0-5cm.tif', 'FC.100-200cm.tif', 'FC.15-30cm.tif', 'FC.30-60cm.tif', 'FC.60-100cm.tif', 'ksat_15-30cm.tif', 'ksat_30-60cm.tif', 'ksat_60-100cm.tif', 'n_15-30cm.tif', 'n_5-15cm.tif', 'PWP.100-200cm.tif', 'PWP.15-30cm.tif', 'PWP.5-15cm.tif', 'theta_r_0-5cm.tif', 'theta_r_30-60cm.tif', 'theta_s_5-15cm.tif', 'theta_s_60-100cm.tif', 'alpha.100-200cm.tif', 'alpha.15-30cm.tif', 'alpha.30-60cm.tif', 'alpha.5-15cm.tif', 'alpha.60-100cm.tif', 'ksat.100-200cm.tif', 'ksat.30-60cm.tif', 'ksat.60-100cm.tif', 'n.100-200cm.tif', 'n.15-30cm.tif', 'n.5-15cm.tif', 'theta_r.15-30cm.tif', 'theta_r.30-60cm.tif', 'theta_r.60-100cm.tif', 'theta_s.100-200cm.tif', 'theta_s.15-30cm.tif', 'theta_s.60-100cm.tif', 'Bulkd.5-15cm.tif', 'Clay.15-30cm.tif', 'Clay.5-15cm.tif', 'Sand.100-200cm.tif', 'Sand.5-15cm.tif', 'Silt.0-5cm.tif', 'Silt.15-30cm.tif', 'Silt.60-100cm.tif', 'Tex_Class.15-30cm.tif', 'Tex_Class.5-15cm.tif', 'Tex_Class.60-100cm.tif', 'PP', 'valor_humedad_suelo1', 'slope']\n"
     ]
    }
   ],
   "source": [
    "# Usar CART para seleccionar características\n",
    "cart_features = cart_feature_selection(df, 'Valor', n_features=5)\n",
    "print(\"Características seleccionadas por CART:\", cart_features)\n",
    "\n",
    "# Usar algoritmo genético para seleccionar características\n",
    "genetic_features = genetic_feature_selection(df, 'Valor')\n",
    "print(\"Características seleccionadas por el algoritmo genético:\", genetic_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['PIRange_Bulkd.0-5cm.tif',\n",
       " 'PIRange_Bulkd.100-200cm.tif',\n",
       " 'PIRange_Bulkd.15-30cm.tif',\n",
       " 'PIRange_Bulkd.30-60cm.tif',\n",
       " 'PIRange_Bulkd.60-100cm.tif',\n",
       " 'PIRange_Clay.0-5cm.tif',\n",
       " 'PIRange_Clay.15-30cm.tif',\n",
       " 'PIRange_Clay.30-60cm.tif',\n",
       " 'PIRange_Sand.0-5cm.tif',\n",
       " 'PIRange_Sand.100-200cm.tif',\n",
       " 'PIRange_Sand.60-100cm.tif',\n",
       " 'alpha_30-60cm.tif',\n",
       " 'alpha_60-100cm.tif',\n",
       " 'AvMoist.0-5cm.tif',\n",
       " 'AWC_0-5cm.tif',\n",
       " 'AWC_100-200cm.tif',\n",
       " 'AWC_5-15cm.tif',\n",
       " 'AWC_60-100cm.tif',\n",
       " 'FC.0-5cm.tif',\n",
       " 'FC.100-200cm.tif',\n",
       " 'FC.15-30cm.tif',\n",
       " 'FC.30-60cm.tif',\n",
       " 'FC.60-100cm.tif',\n",
       " 'ksat_15-30cm.tif',\n",
       " 'ksat_30-60cm.tif',\n",
       " 'ksat_60-100cm.tif',\n",
       " 'n_15-30cm.tif',\n",
       " 'n_5-15cm.tif',\n",
       " 'PWP.100-200cm.tif',\n",
       " 'PWP.15-30cm.tif',\n",
       " 'PWP.5-15cm.tif',\n",
       " 'theta_r_0-5cm.tif',\n",
       " 'theta_r_30-60cm.tif',\n",
       " 'theta_s_5-15cm.tif',\n",
       " 'theta_s_60-100cm.tif',\n",
       " 'alpha.100-200cm.tif',\n",
       " 'alpha.15-30cm.tif',\n",
       " 'alpha.30-60cm.tif',\n",
       " 'alpha.5-15cm.tif',\n",
       " 'alpha.60-100cm.tif',\n",
       " 'ksat.100-200cm.tif',\n",
       " 'ksat.30-60cm.tif',\n",
       " 'ksat.60-100cm.tif',\n",
       " 'n.100-200cm.tif',\n",
       " 'n.15-30cm.tif',\n",
       " 'n.5-15cm.tif',\n",
       " 'theta_r.15-30cm.tif',\n",
       " 'theta_r.30-60cm.tif',\n",
       " 'theta_r.60-100cm.tif',\n",
       " 'theta_s.100-200cm.tif',\n",
       " 'theta_s.15-30cm.tif',\n",
       " 'theta_s.60-100cm.tif',\n",
       " 'Bulkd.5-15cm.tif',\n",
       " 'Clay.15-30cm.tif',\n",
       " 'Clay.5-15cm.tif',\n",
       " 'Sand.100-200cm.tif',\n",
       " 'Sand.5-15cm.tif',\n",
       " 'Silt.0-5cm.tif',\n",
       " 'Silt.15-30cm.tif',\n",
       " 'Silt.60-100cm.tif',\n",
       " 'Tex_Class.15-30cm.tif',\n",
       " 'Tex_Class.5-15cm.tif',\n",
       " 'Tex_Class.60-100cm.tif',\n",
       " 'PP',\n",
       " 'valor_humedad_suelo1',\n",
       " 'slope']"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "genetic_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Características seleccionadas por CART: ['PIRange_Bulkd.5-15cm.tif', 'PIRange_Clay.0-5cm.tif', 'ksat_30-60cm.tif', 'valor_humedad_suelo1', 'PIRange_Sand.5-15cm.tif', 'FC.0-5cm.tif', 'PWP.15-30cm.tif', 'alpha_60-100cm.tif', 'ksat_5-15cm.tif', 'Sand.100-200cm.tif', 'n_30-60cm.tif', 'PP', 'AWC_60-100cm.tif', 'PWP.100-200cm.tif', 'PIRange_Bulkd.60-100cm.tif', 'PIRange_Bulkd.15-30cm.tif', 'FC.30-60cm.tif', 'theta_s_100-200cm.tif', 'PIRange_Sand.100-200cm.tif', 'Bulkd.100-200cm.tif']\n"
     ]
    }
   ],
   "source": [
    "cart_features = cart_feature_selection(df, 'Valor', n_features=20)\n",
    "print(\"Características seleccionadas por CART:\", cart_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_cart_features = cart_features\n",
    "#new_cart_features.append('PP')\n",
    "new_cart_features.append('slope')\n",
    "#new_cart_features.append('valor_humedad_suelo1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['PIRange_Bulkd.5-15cm.tif',\n",
       " 'PIRange_Clay.0-5cm.tif',\n",
       " 'ksat_30-60cm.tif',\n",
       " 'valor_humedad_suelo1',\n",
       " 'PIRange_Sand.5-15cm.tif',\n",
       " 'FC.0-5cm.tif',\n",
       " 'PWP.15-30cm.tif',\n",
       " 'alpha_60-100cm.tif',\n",
       " 'ksat_5-15cm.tif',\n",
       " 'Sand.100-200cm.tif',\n",
       " 'n_30-60cm.tif',\n",
       " 'PP',\n",
       " 'AWC_60-100cm.tif',\n",
       " 'PWP.100-200cm.tif',\n",
       " 'PIRange_Bulkd.60-100cm.tif',\n",
       " 'PIRange_Bulkd.15-30cm.tif',\n",
       " 'FC.30-60cm.tif',\n",
       " 'theta_s_100-200cm.tif',\n",
       " 'PIRange_Sand.100-200cm.tif',\n",
       " 'Bulkd.100-200cm.tif',\n",
       " 'slope']"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cart_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[cart_features]\n",
    "y = df.Valor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numero de entrenamiendo: (856, 15), Numero de test: (214, 15)\n",
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n",
      "Precisión de 91.1214953271028\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "param_grid = {\n",
    "    'max_depth': [3, 5, 7, 10],\n",
    "    'learning_rate': [0.01, 0.1, 0.2, 0.3],\n",
    "    'n_estimators': [100, 200, 300, 500],\n",
    "    'subsample': [0.6, 0.8, 1.0],\n",
    "    'colsample_bytree': [0.6, 0.8, 1.0],\n",
    "    'gamma': [0, 0.1, 0.2, 0.3],\n",
    "    'reg_alpha': [0, 0.1, 0.5, 1.0],\n",
    "    'reg_lambda': [0, 1.0, 10.0]\n",
    "}\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "print(f'Numero de entrenamiendo: {X_train.shape}, Numero de test: {X_test.shape}')\n",
    "model = XGBClassifier()\n",
    "random_search = RandomizedSearchCV(model, param_distributions=param_grid, n_iter=50, scoring='accuracy', cv=5, verbose=1, random_state=42)\n",
    "random_search.fit(X_train, y_train)\n",
    "best_model = random_search.best_estimator_\n",
    "y_pred = best_model.predict(X_test)\n",
    "acc = accuracy_score(y_true=y_test, y_pred=y_pred)\n",
    "print(f'Precisión de {acc*100}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from deap import creator, base, tools, algorithms\n",
    "\n",
    "def enhanced_genetic_feature_selection(df, target_column, n_generations=100, population_size=50):\n",
    "    # Paso 1: Eliminar variables correlacionadas\n",
    "    def remove_correlated_features(X, threshold=0.95):\n",
    "        corr_matrix = X.corr().abs()\n",
    "        upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(bool))\n",
    "        to_drop = [column for column in upper.columns if any(upper[column] > threshold)]\n",
    "        return X.drop(to_drop, axis=1)\n",
    "\n",
    "    # Paso 2: Aplicar CART para eliminar variables menos significativas\n",
    "    def select_features_with_cart(X, y, max_features=50):\n",
    "        clf = DecisionTreeClassifier(random_state=42)\n",
    "        selector = SelectFromModel(clf, max_features=max_features)\n",
    "        selector = selector.fit(X, y)\n",
    "        return X.columns[selector.get_support()].tolist()\n",
    "\n",
    "    # Preprocesamiento\n",
    "    X = df.drop(target_column, axis=1)\n",
    "    y = df[target_column]\n",
    "    X = remove_correlated_features(X)\n",
    "    selected_features = select_features_with_cart(X, y)\n",
    "    X = X[selected_features]\n",
    "\n",
    "    # Configuración del algoritmo genético\n",
    "    creator.create(\"FitnessMin\", base.Fitness, weights=(-1.0,))\n",
    "    creator.create(\"Individual\", list, fitness=creator.FitnessMin)\n",
    "\n",
    "    toolbox = base.Toolbox()\n",
    "    toolbox.register(\"attr_bool\", np.random.randint, 0, 2)\n",
    "    toolbox.register(\"individual\", tools.initRepeat, creator.Individual, toolbox.attr_bool, n=len(X.columns))\n",
    "    toolbox.register(\"population\", tools.initRepeat, list, toolbox.individual)\n",
    "\n",
    "    def evaluate(individual):\n",
    "        selected_features = X.columns[np.array(individual, dtype=bool)]\n",
    "        if len(selected_features) == 0:\n",
    "            return float('inf'),\n",
    "        clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "        scores = cross_val_score(clf, X[selected_features], y, cv=5, scoring='neg_mean_squared_error')\n",
    "        mse = -np.mean(scores)\n",
    "        penalty = len(selected_features) / len(X.columns)\n",
    "        return mse + penalty,\n",
    "\n",
    "    toolbox.register(\"evaluate\", evaluate)\n",
    "    toolbox.register(\"mate\", tools.cxTwoPoint)\n",
    "    toolbox.register(\"mutate\", tools.mutFlipBit, indpb=0.05)\n",
    "    toolbox.register(\"select\", tools.selTournament, tournsize=3)\n",
    "\n",
    "    population = toolbox.population(n=population_size)\n",
    "    \n",
    "    stats = tools.Statistics(lambda ind: ind.fitness.values)\n",
    "    stats.register(\"avg\", np.mean)\n",
    "    stats.register(\"min\", np.min)\n",
    "    \n",
    "    hof = tools.HallOfFame(1)\n",
    "    \n",
    "    final_pop, logbook = algorithms.eaSimple(population, toolbox, cxpb=0.9, mutpb=0.1, \n",
    "                                             ngen=n_generations, stats=stats, halloffame=hof, verbose=True)\n",
    "\n",
    "    best_individual = hof[0]\n",
    "    final_selected_features = X.columns[np.array(best_individual, dtype=bool)].tolist()\n",
    "\n",
    "    return final_selected_features, logbook\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gen\tnevals\tavg     \tmin     \n",
      "0  \t50    \t0.673167\t0.474039\n",
      "1  \t50    \t0.589678\t0.444133\n",
      "2  \t43    \t0.520058\t0.387227\n",
      "3  \t42    \t0.463178\t0.365317\n",
      "4  \t41    \t0.434787\t0.331672\n",
      "5  \t50    \t0.404787\t0.331672\n",
      "6  \t44    \t0.369688\t0.331672\n",
      "7  \t46    \t0.357136\t0.298962\n",
      "8  \t46    \t0.340903\t0.298962\n",
      "9  \t50    \tinf     \t0.298962\n",
      "10 \t48    \tinf     \t0.298962\n",
      "11 \t42    \tinf     \t0.298962\n",
      "12 \t48    \t0.31125 \t0.298962\n",
      "13 \t46    \t0.304754\t0.298962\n",
      "14 \t44    \t0.301261\t0.298962\n"
     ]
    }
   ],
   "source": [
    "selected_features, logbook = enhanced_genetic_feature_selection(df, 'Valor')\n",
    "print(\"Características seleccionadas:\", selected_features)\n",
    "print(\"Evolución del fitness:\", logbook)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "geotiff",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
