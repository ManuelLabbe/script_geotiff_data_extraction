{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def cart_feature_selection(df, target_column, n_features=5):\n",
    "    X = df.drop(target_column, axis=1)\n",
    "    y = df[target_column]\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    \n",
    "    cart = DecisionTreeClassifier(random_state=42)\n",
    "    cart.fit(X_train, y_train)\n",
    "    \n",
    "    feature_importance = pd.DataFrame({\n",
    "        'feature': X.columns,\n",
    "        'importance': cart.feature_importances_\n",
    "    }).sort_values('importance', ascending=False)\n",
    "    \n",
    "    selected_features = feature_importance['feature'][:n_features].tolist()\n",
    "    \n",
    "    return selected_features\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from deap import creator, base, tools, algorithms\n",
    "\n",
    "def genetic_feature_selection(df, target_column, n_generations=50, population_size=50):\n",
    "    X = df.drop(target_column, axis=1)\n",
    "    y = df[target_column]\n",
    "\n",
    "    creator.create(\"FitnessMax\", base.Fitness, weights=(1.0,))\n",
    "    creator.create(\"Individual\", list, fitness=creator.FitnessMax)\n",
    "\n",
    "    toolbox = base.Toolbox()\n",
    "    toolbox.register(\"attr_bool\", np.random.randint, 0, 2)\n",
    "    toolbox.register(\"individual\", tools.initRepeat, creator.Individual, toolbox.attr_bool, n=len(X.columns))\n",
    "    toolbox.register(\"population\", tools.initRepeat, list, toolbox.individual)\n",
    "\n",
    "    def evaluate(individual):\n",
    "        selected_features = X.columns[np.array(individual, dtype=bool)]\n",
    "        if len(selected_features) == 0:\n",
    "            return 0,\n",
    "        clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "        scores = cross_val_score(clf, X[selected_features], y, cv=5)\n",
    "        return np.mean(scores),\n",
    "\n",
    "    toolbox.register(\"evaluate\", evaluate)\n",
    "    toolbox.register(\"mate\", tools.cxTwoPoint)\n",
    "    toolbox.register(\"mutate\", tools.mutFlipBit, indpb=0.05)\n",
    "    toolbox.register(\"select\", tools.selTournament, tournsize=3)\n",
    "\n",
    "    population = toolbox.population(n=population_size)\n",
    "    algorithms.eaSimple(population, toolbox, cxpb=0.5, mutpb=0.2, ngen=n_generations, verbose=False)\n",
    "\n",
    "    best_individual = tools.selBest(population, k=1)[0]\n",
    "    selected_features = X.columns[np.array(best_individual, dtype=bool)].tolist()\n",
    "\n",
    "    return selected_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_1 = pd.read_csv('New_DB_2.csv')\n",
    "db_0 = pd.read_csv('New_DB_0.csv')\n",
    "db_1 = db_1.drop(columns='Valor')\n",
    "db_0 = db_0.drop(columns='Valor')\n",
    "db_1['Fecha Evento'] = pd.to_datetime(db_1['Fecha Evento'], format='%d/%m/%Y', errors='coerce')\n",
    "db_0['Fecha Evento'] = pd.to_datetime(db_0['Fecha Evento'], format='%d/%m/%Y', errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw = pd.read_csv('data_processed.csv')\n",
    "raw = raw.drop_duplicates(subset=['Latitud', 'Longitud', 'Fecha Evento'])\n",
    "raw = raw.reset_index()\n",
    "raw['Fecha Evento'] = pd.to_datetime(raw['Fecha Evento'], format='%d/%m/%Y', errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((602, 137), (602, 137))"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_1 = pd.read_csv('test_data_1')\n",
    "df_0 = pd.read_csv('test_data_0_2')\n",
    "df_1 = df_1.drop(columns=['Unnamed: 0.1', 'Unnamed: 0'])\n",
    "df_0 = df_0.drop(columns=['Unnamed: 0'])\n",
    "df_1['Valor'] = 1\n",
    "df_0['Valor'] = 0\n",
    "df_1['Fecha Evento'] = raw['Fecha Evento']\n",
    "df_0['Fecha Evento'] = raw['Fecha Evento']\n",
    "#df_1['Fecha Evento'] = pd.to_datetime(df_1['Fecha Evento'], format='%d/%m/%Y', errors='coerce')\n",
    "#df_0['Fecha Evento'] = pd.to_datetime(df_0['Fecha Evento'], format='%d/%m/%Y', errors='coerce')\n",
    "df_1.shape, df_0.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_0 = pd.merge(df_0 , db_0, on=['Latitud', 'Longitud', 'Fecha Evento'], how='inner')\n",
    "df_1 = pd.merge(df_1 , db_1, on=['Latitud', 'Longitud', 'Fecha Evento'], how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1 = df_1.drop(columns=['valor_humedad_suelo2','valor_humedad_suelo3', 'valor_humedad_suelo4',\n",
    "       'Tipo Remoción en masa', 'Unnamed: 0','Región', 'Comuna', 'Factor desencadenante',\n",
    "       'Sistema Georeferencia', 'Cota (m.s.n.m)', 'Fecha Evento'])\n",
    "df_0 = df_0.drop(columns=['valor_humedad_suelo2','valor_humedad_suelo3', 'valor_humedad_suelo4',\n",
    "       'Tipo Remoción en masa', 'Unnamed: 0','Región', 'Comuna', 'Factor desencadenante',\n",
    "       'Sistema Georeferencia', 'Cota (m.s.n.m)', 'Fecha Evento'])\n",
    "df_1 = df_1.fillna(df_1.mean())\n",
    "df_0 = df_0.fillna(df_0.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1070, 136), (1070,))"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.concat([df_0,df_1])\n",
    "df = df.drop(columns=['Longitud', 'Latitud'])\n",
    "df_x = df.drop(columns='Valor')\n",
    "df_y = df.Valor\n",
    "df_x.shape, df_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Características seleccionadas por CART: ['PIRange_Bulkd.5-15cm.tif', 'PIRange_Clay.0-5cm.tif', 'ksat_30-60cm.tif', 'valor_humedad_suelo1', 'PIRange_Sand.5-15cm.tif']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ivo\\.conda\\envs\\geotiff\\lib\\site-packages\\deap\\creator.py:185: RuntimeWarning: A class named 'FitnessMax' has already been created and it will be overwritten. Consider deleting previous creation of that class or rename it.\n",
      "  warnings.warn(\"A class named '{0}' has already been created and it \"\n",
      "c:\\Users\\ivo\\.conda\\envs\\geotiff\\lib\\site-packages\\deap\\creator.py:185: RuntimeWarning: A class named 'Individual' has already been created and it will be overwritten. Consider deleting previous creation of that class or rename it.\n",
      "  warnings.warn(\"A class named '{0}' has already been created and it \"\n"
     ]
    }
   ],
   "source": [
    "# Usar CART para seleccionar características\n",
    "cart_features = cart_feature_selection(df, 'Valor', n_features=5)\n",
    "print(\"Características seleccionadas por CART:\", cart_features)\n",
    "\n",
    "# Usar algoritmo genético para seleccionar características\n",
    "genetic_features = genetic_feature_selection(df, 'Valor')\n",
    "print(\"Características seleccionadas por el algoritmo genético:\", genetic_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Características seleccionadas por CART: ['PIRange_Bulkd.5-15cm.tif', 'PIRange_Clay.0-5cm.tif', 'ksat_30-60cm.tif', 'ksat_5-15cm.tif', 'PIRange_Sand.5-15cm.tif', 'PWP.0-5cm.tif', 'n_15-30cm.tif', 'PIRange_Bulkd.30-60cm.tif', 'PIRange_Clay.15-30cm.tif', 'n_30-60cm.tif']\n"
     ]
    }
   ],
   "source": [
    "cart_features = cart_feature_selection(df, 'Valor', n_features=10)\n",
    "print(\"Características seleccionadas por CART:\", cart_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[genetic_features]\n",
    "y = df.Valor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numero de entrenamiendo: (963, 60), Numero de test: (241, 60)\n",
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n",
      "Precisión de 89.62655601659752\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "param_grid = {\n",
    "    'max_depth': [3, 5, 7, 10],\n",
    "    'learning_rate': [0.01, 0.1, 0.2, 0.3],\n",
    "    'n_estimators': [100, 200, 300, 500],\n",
    "    'subsample': [0.6, 0.8, 1.0],\n",
    "    'colsample_bytree': [0.6, 0.8, 1.0],\n",
    "    'gamma': [0, 0.1, 0.2, 0.3],\n",
    "    'reg_alpha': [0, 0.1, 0.5, 1.0],\n",
    "    'reg_lambda': [0, 1.0, 10.0]\n",
    "}\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "print(f'Numero de entrenamiendo: {X_train.shape}, Numero de test: {X_test.shape}')\n",
    "model = XGBClassifier()\n",
    "random_search = RandomizedSearchCV(model, param_distributions=param_grid, n_iter=50, scoring='accuracy', cv=5, verbose=1, random_state=42)\n",
    "random_search.fit(X_train, y_train)\n",
    "best_model = random_search.best_estimator_\n",
    "y_pred = best_model.predict(X_test)\n",
    "acc = accuracy_score(y_true=y_test, y_pred=y_pred)\n",
    "print(f'Precisión de {acc*100}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "geotiff",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
